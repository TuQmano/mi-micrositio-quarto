[
  {
    "objectID": "encuesta.html",
    "href": "encuesta.html",
    "title": "Encuesta Nacional sobre Adopci√≥n de IA",
    "section": "",
    "text": "INFORMES:\nüìÑ ARGENTINA\n‚¨áÔ∏è Descargar\nüìÑ URUGUAY\n‚¨áÔ∏è Descargar\n\n\n\n¬øPor qu√© una encuesta sobre usos de IA?\nEl mundo ya no es el que conoc√≠amos. La inteligencia artificial est√° transformando la econom√≠a y la vida cotidiana a un ritmo acelerado, amplificando desigualdades o creando oportunidades. La poblaci√≥n muestra sentimientos encontrados: entusiasmo y expectativas altas, pero tambi√©n nerviosismo y dudas sobre privacidad, discriminaci√≥n y p√©rdida de empleo. La adopci√≥n de IA en las empresas avanza r√°pidamente. Pero lo hace de manera profundamente heterog√©nea, segmentada y desigual porque no todas tienen las capacidades y los recursos para adoptar nuevas tecnolog√≠as¬†\nEn Argentina, la situaci√≥n es a√∫n m√°s compleja: no contamos con datos b√°sicos. ¬øCu√°l es el nivel de adopci√≥n? ¬øQui√©nes la usan y para qu√©? ¬øC√≥mo impacta en la vida cotidiana de las personas? ¬øQu√© grupos sociales est√°n accediendo m√°s r√°pidamente y cu√°les permanecen rezagados? ¬øQu√© porcentaje de empresas usa IA? ¬øEn qu√© sectores y con qu√© fines? ¬øQu√© barreras enfrentan para incorporarla? ¬øQu√© regulaciones necesitamos para asegurar un desarrollo responsable y competitivo? ¬øQui√©nes deber√≠an liderarla?\nLo que s√≠ sabemos es que el impacto de la IA va a depender de las decisiones que tomemos hoy y de las pol√≠ticas que implementemos y que para eso necesitamos datos. Porque queremos¬† una IA que sirva para aumentar la productividad, crecer y competir internacionalmente. Que genere m√°s trabajo de calidad, calificado y m√°s bienestar en la sociedad. Con esta misi√≥n, desde el CEPE-Di Tella y Fundar realizamos una encuesta con un panel online con cuotas por g√©nero, nivel educativo, edad, nivel socioecon√≥mico y regi√≥n para aproximar la composici√≥n de la poblaci√≥n adulta (18 a√±os o m√°s), recolectadas entre agosto y septiembre de 2025 en Argentina y Uruguay.\nLa encuesta se centra espec√≠ficamente en el uso (personal y laboral) de la inteligencia artificial generativa, entendiendo por √©sta a ‚Äúsistemas que crean textos, im√°genes o c√≥digos autom√°ticamente‚Äù. Adem√°s de indagar en los planos personales y laborales del uso de IA generativa, la encuesta explor√≥ dimensiones como el nivel de confianza, conocimiento, perspectivas y sentimientos respecto a esta herramienta."
  },
  {
    "objectID": "investigacion.html",
    "href": "investigacion.html",
    "title": "Investigaci√≥n",
    "section": "",
    "text": "Encuesta Nacional sobre Adopci√≥n de IA - Individuos\n\nArgentina y Uruguay 2025\n\n\nEncuesta sobre el uso personal y laboral de inteligencia artificial generativa en Argentina y Uruguay. An√°lisis de adopci√≥n, confianza, conocimiento y perspectivas de la poblaci√≥n adulta.\n\nVer investigaci√≥n ‚Üí\n\n\nEncuesta Nacional sobre Adopci√≥n de IA - PyMES\n\nArgentina En desarrollo\n\n\nInvestigaci√≥n sobre la adopci√≥n de inteligencia artificial en peque√±as y medianas empresas argentinas. An√°lisis de barreras, oportunidades y estrategias de implementaci√≥n.\n\nVer investigaci√≥n ‚Üí"
  },
  {
    "objectID": "investigacion/encuesta-individuos.html",
    "href": "investigacion/encuesta-individuos.html",
    "title": "Encuesta Nacional sobre Adopci√≥n de IA - Individuos",
    "section": "",
    "text": "INFORMES:\nüìÑ ARGENTINA\n‚¨áÔ∏è Descargar\nüìÑ URUGUAY\n‚¨áÔ∏è Descargar\n\n\n¬øPor qu√© una encuesta sobre usos de IA?\nEl mundo ya no es el que conoc√≠amos. La inteligencia artificial est√° transformando la econom√≠a y la vida cotidiana a un ritmo acelerado, amplificando desigualdades o creando oportunidades. La poblaci√≥n muestra sentimientos encontrados: entusiasmo y expectativas altas, pero tambi√©n nerviosismo y dudas sobre privacidad, discriminaci√≥n y p√©rdida de empleo. La adopci√≥n de IA en las empresas avanza r√°pidamente. Pero lo hace de manera profundamente heterog√©nea, segmentada y desigual porque no todas tienen las capacidades y los recursos para adoptar nuevas tecnolog√≠as.\nEn Argentina, la situaci√≥n es a√∫n m√°s compleja: no contamos con datos b√°sicos. ¬øCu√°l es el nivel de adopci√≥n? ¬øQui√©nes la usan y para qu√©? ¬øC√≥mo impacta en la vida cotidiana de las personas? ¬øQu√© grupos sociales est√°n accediendo m√°s r√°pidamente y cu√°les permanecen rezagados? ¬øQu√© porcentaje de empresas usa IA? ¬øEn qu√© sectores y con qu√© fines? ¬øQu√© barreras enfrentan para incorporarla? ¬øQu√© regulaciones necesitamos para asegurar un desarrollo responsable y competitivo? ¬øQui√©nes deber√≠an liderarla?\nLo que s√≠ sabemos es que el impacto de la IA va a depender de las decisiones que tomemos hoy y de las pol√≠ticas que implementemos y que para eso necesitamos datos. Porque queremos una IA que sirva para aumentar la productividad, crecer y competir internacionalmente. Que genere m√°s trabajo de calidad, calificado y m√°s bienestar en la sociedad. Con esta misi√≥n, desde el CEPE-Di Tella y Fundar realizamos una encuesta con un panel online con cuotas por g√©nero, nivel educativo, edad, nivel socioecon√≥mico y regi√≥n para aproximar la composici√≥n de la poblaci√≥n adulta (18 a√±os o m√°s), recolectadas entre agosto y septiembre de 2025 en Argentina y Uruguay.\nLa encuesta se centra espec√≠ficamente en el uso (personal y laboral) de la inteligencia artificial generativa, entendiendo por √©sta a ‚Äúsistemas que crean textos, im√°genes o c√≥digos autom√°ticamente‚Äù. Adem√°s de indagar en los planos personales y laborales del uso de IA generativa, la encuesta explor√≥ dimensiones como el nivel de confianza, conocimiento, perspectivas y sentimientos respecto a esta herramienta."
  },
  {
    "objectID": "posts/una-inteligencia-artificial-que-hable-nuestro-idioma.html",
    "href": "posts/una-inteligencia-artificial-que-hable-nuestro-idioma.html",
    "title": "Una inteligencia artificial que hable nuestro idioma",
    "section": "",
    "text": "‚ÄúDime c√≥mo hablas y te dir√© de d√≥nde vienes‚Äù, podr√≠a susurrar un algoritmo. Cuando ChatGPT describe nuestra cultura como ‚Äúvibrante, diversa, arraigada en herencia ind√≠gena, africana y europea‚Äù, uno no sabe si aplaudir la correcci√≥n pol√≠tica o lamentar la blandura de postal tur√≠stica. El problema trasciende la cortes√≠a: estos cerebros artificiales tropiezan con nuestros c√≥digos locales, no entienden que ‚Äúnos vemos‚Äù en Buenos Aires es una promesa et√©rea, confunden las siglas cambiantes de la burocracia territorial o alucinan palabras en guaran√≠ con la desenvoltura de un colonizador digital.\nUn grupo de ingenieros est√° construyendo una respuesta a esto: LatamGPT, el primer modelo de inteligencia artificial dise√±ado espec√≠ficamente para nuestra regi√≥n, que tiene lanzamiento programado para 2025. El proyecto, coordinado desde Chile por el Centro Nacional de Inteligencia Artificial (Cenia), plantea una pregunta que roza lo existencial: ¬øpuede una regi√≥n que siempre lleg√≥ tarde al cambio tecnol√≥gico escribir su propio guion digital? Con 33 alianzas estrat√©gicas firmadas en 2024 que incluyen a 12 pa√≠ses ‚Äîy el respaldo de Brasil, que comprometi√≥ cerca de US$4000 millones para su plan de IA de 2024-2028‚Äî, el proyecto trasciende la fantas√≠a tecnopatri√≥tica.\nLatamGPT promete una revoluci√≥n silenciosa: entre 50.000 y 70.000 millones de par√°metros entrenados con 8 terabytes de datos del barrio latinoamericano. Decisiones judiciales de tribunales porte√±os, registros bibliotecarios de Lima, libros de texto de Bogot√° y lenguas ancestrales como el n√°huatl, el quechua y el mapudungun alimentar√°n sus neuronas artificiales. Imaginemos un modelo que no solo traduzca, sino que adem√°s comprenda la diferencia entre un pibe porte√±o, un cara carioca, un pelado bogotano, un cabro santiaguino, un chavo chilango, un chibolo lime√±o, un botija montevideano. Un algoritmo que, all√≠ donde ChatGPT responde con la fr√≠a genericidad de ‚Äútr√°mites gubernamentales‚Äù, pueda navegar las particularidades del PIX brasile√±o, desentra√±ar los misterios del CURP mexicano o seguir la danza de siglas y colores del Estado y la pol√≠tica argentinos (de la AFIP a la ARCA, de celeste a violeta).\nLo que comenz√≥ como experimento acad√©mico mut√≥ en obsesi√≥n continental. Brasil lidera con √©pica sudamericana; con su Plan de IA 2024-2028, distribuye 23.000 millones de reales en cuatro a√±os, casi 14.000 millones para innovaci√≥n empresarial y m√°s de 5000 millones para infraestructura. Colombia aprob√≥ el Conpes 4144, un plan de US$479 millones en seis a√±os que promete digitalizar hasta el √∫ltimo rinc√≥n rural. Chile anunci√≥ US$2500 millones para 28 centros de datos; seg√∫n el √çndice Latinoamericano de Inteligencia Artificial 2024 de la Cepal, el pa√≠s mapuche ocupa el primer lugar, seguido por Brasil y Uruguay. La delantera chilena no es casualidad. El Centro Binacional Franco-Chileno de Inteligencia Artificial, inaugurado en febrero de 2025 tras el acuerdo entre Boric y Macron, materializa una cooperaci√≥n que aporta el savoir faire franc√©s del Inria. El centro de supercomputaci√≥n de la Universidad de Tarapac√°, con sus US$10.000.000 de inversi√≥n y energ√≠a renovable del desierto de Atacama, hospeda hoy el futuro latinoamericano.\nChile fue tambi√©n pionero en completar la Metodolog√≠a de Evaluaci√≥n de Preparaci√≥n para IA de la Unesco, actualizando su pol√≠tica nacional en 2024 con √©nfasis en transparencia y equidad. Su proyecto de ley de 2024 crea consejos asesores t√©cnicos y marcos basados en riesgo, anticip√°ndose a la mayor√≠a regional con esa vocaci√≥n regulatoria que nos distingue de la anarqu√≠a californiana. En paralelo, las comunidades ind√≠genas escriben su propia √©pica digital. El Proyecto Illary de Per√∫ cre√≥ el primer avatar presentador de noticias del mundo en quechua, con 80-90% de precisi√≥n, migrando desde aulas universitarias hasta la viralidad de TikTok, prueba de que la tecnolog√≠a puede ser puente, no sepultura, de nuestras lenguas originarias.\nEn Brasil, la alianza entre IBM Research y la comunidad guaran√≠ Tenonde Por√£ produjo un ‚Äúasistente ling√º√≠stico‚Äù que ayud√≥ a 30 estudiantes de secundaria a escribir oraciones m√°s complejas en mby√° guaran√≠ despu√©s de un semestre. Un modelo escalable a las 190 lenguas ind√≠genas brasile√±as que enfrentan riesgo de extinci√≥n, tecnolog√≠a como arqueolog√≠a del futuro. M√©xico desarrolla cinco proyectos documentados por la Unesco, incluidos protecci√≥n de patrones textiles con IA para comunidades de Altos de Chiapas y sistemas de traducci√≥n multiling√ºe que abrazan 11 familias de lenguas ind√≠genas. Google News Initiative apoya proyectos como Quispe Chequea de Per√∫, que crea contenido en quechua, aimara y awaj√∫n para 12 estaciones de radio amaz√≥nicas y andinas.\nLa pregunta persiste: ¬øsoberan√≠a digital o autoenga√±o en tecnicolor? Con una inversi√≥n regional de US$8200 millones frente a los US$190.000 millones globales, las proporciones sugieren m√°s David que Goliat. La aparici√≥n de alternativas como DeepSeek ‚Äîque exhibe rendimiento superior a ChatGPT en traducci√≥n al espa√±ol en ciertas pruebas‚Äî redefine el tablero. De repente, el acceso rentable a IA de calidad no requiere ciudadan√≠a californiana. Y los modelos peque√±os de fuente abierta se vuelven moda. ¬øDebemos partir de uno de estos modelos y ‚Äúecualizarlo‚Äù para que cante con nuestras voces, a riesgo de quedar atrapados en una suscripci√≥n ascendente como el protagonista del episodio ‚ÄúCommon People‚Äù de la √∫ltima temporada de Black Mirror? ¬øConviene empezar de cero con un modelo nuestro americano dif√≠cil de crear y costoso de mantener?\nSuiza eligi√≥ la soberan√≠a total con su modelo multiling√ºe de c√≥digo abierto para 2025, demostrando que la IA nacional es t√©cnicamente viable ‚Äîcon condiciones de peso: inversi√≥n p√∫blica sostenida, coordinaci√≥n institucional militar, capacidad centralizada suiza; para el resto de nosotros, la alternativa pragm√°tica parecer√≠a ser la adaptaci√≥n inteligente‚Äî en l√≠nea con el camino adoptado por LatamGPT. T√©cnicas como LoRA (Low-Rank Adaptation) permiten personalizar modelos existentes para contextos regionales con una fracci√≥n del costo computacional; la alquimia de convertir inteligencia artificial ajena en propia sin quebrar el tesoro p√∫blico. Aqu√≠, las alianzas estrat√©gicas son vitales: Microsoft-Kyndryl expandiendo su Centro de Excelencia regional, Amazon prometiendo US$1800 millones para centros de datos brasile√±os, la Alianza Digital UE-ALC facilitando transferencia tecnol√≥gica, Google Startup Accelerator AI First ofreciendo hasta US$350.000 en cr√©ditos de nube para participantes brasile√±os.\nJ.P. Morgan estima una oportunidad de US$100.000 millones durante la pr√≥xima d√©cada para la econom√≠a de servicios de IA en Am√©rica Latina. Los banqueros, cuando olfatean ganancias, rara vez se equivocan. LatamGPT tambi√©n nos obliga a repensar una herej√≠a: si la conectividad digital es el ferrocarril del siglo XXI y la IA, el motor de la era posindustrial, ¬øpor qu√© el Estado observa desde las gradas? La infraestructura sol√≠a significar cemento y acero. Hoy incluye GPU y datasets estructurados. El experimento LatamGPT testea si la IA puede funcionar como infraestructura p√∫blica: gestionada para beneficio colectivo, no rentabilidad privada.\nEsto subvierte en parte sus criterios de √©xito. Mientras la IA comercial persigue engagement adictivo, el modelo p√∫blico deber√≠a servir a la educaci√≥n, la salud, la preservaci√≥n cultural. Por ejemplo, si la IA puede reducir la deserci√≥n escolar y optimizar servicios de salud p√∫blica, el entrenamiento con datos regionales deber√≠a volverla m√°s efectiva que alternativas globales para contextos locales, justificando la inversi√≥n p√∫blica como inversi√≥n en futuro, no en prestigio. ¬øQu√© hace falta para que los gobiernos de la regi√≥n entiendan que la IA va camino a ser un servicio b√°sico como la educaci√≥n, la salud o el transporte, y deber√≠a ser tratada del mismo modo?\nEl lanzamiento de LatamGPT ser√° el primer examen real que probar√° si Am√©rica Latina puede escribir su propio libreto en la era de la IA. Los factores de √©xito se perfilan n√≠tidamente: inversi√≥n gubernamental sustancial, cooperaci√≥n regional in√©dita, desarrollo comunitario para poblaciones ind√≠genas, y posicionamiento estrat√©gico en aplicaciones especializadas antes que competencia frontal. En suma, un quiebre con las modas pol√≠ticas de la historia reciente. El √©xito se medir√° no en benchmarks t√©cnicos, sino en transformaci√≥n social. Si el modelo ayuda a una maestra rural de Nari√±o o a un funcionario de Ecatepec a trabajar mejor, habr√° justificado su existencia independientemente de cu√°ntos par√°metros tenga o qu√© tan r√°pido procese.\nLa soberan√≠a de IA latinoamericana depender√° de la voluntad pol√≠tica para la inversi√≥n tecnol√≥gica sostenida y la capacidad institucional para mantenerla. LatamGPT ofrece un comienzo prometedor, pero, como toda promesa latinoamericana, la prueba est√° en la perseverancia de la ejecuci√≥n, no en el anuncio. El objetivo no es competir con Silicon Valley, sino construir una IA que nos sirva. En un mundo donde los algoritmos moldean nuestras percepciones de la realidad, tener una IA que entienda la nuestra no es un lujo tecnol√≥gico: es supervivencia cultural. Como dir√≠a un algoritmo criollo: ‚ÄúNo se trata de hablar como ellos, sino de que nos entiendan como somos‚Äù.\n\nPublicado originalmente en La Naci√≥n\n\n\n\n\nTodas Pol√≠ticas P√∫blicas Regulaci√≥n Tecnolog√≠a Educaci√≥n Pol√≠tica Deepfakes Democracia Innovaci√≥n Regi√≥n"
  },
  {
    "objectID": "posts/sturzenegger-argentina-no-necesita-ley-ia.html",
    "href": "posts/sturzenegger-argentina-no-necesita-ley-ia.html",
    "title": "Federico Sturzenegger tiene raz√≥n: Argentina no necesita una ley de inteligencia artificial",
    "section": "",
    "text": "M√°s que una ley de IA, la Argentina necesita reglas claras que ordenen el uso de la tecnolog√≠a, eviten abusos y acompa√±en el desarrollo sin frenar la innovaci√≥n.\nLo que necesitamos son leyes que eviten el mal uso de las tecnolog√≠as ‚Äîm√°s all√° de que sean inteligencia artificial o no‚Äî y que fomenten su adopci√≥n estrat√©gica, al tiempo que contribuyan al desarrollo del pa√≠s.\nNecesitamos leyes que sancionen la publicaci√≥n de videos y fotos pornogr√°ficas con caras de otras personas. Que dificulten las estafas que hoy se apoyan en im√°genes, videos o audios falsos para simular secuestros virtuales o realizar enga√±os cada vez m√°s sofisticados. Que definan responsabilidades cuando un auto, dron o robot aut√≥nomo mata o lastima a alguien.\nTambi√©n necesitamos decidir si queremos sistemas de reconocimiento facial y hasta qu√© punto el Estado puede saber c√≥mo se mueve cada ciudadano, equilibrando seguridad y privacidad. Y, sobre todo, leyes modernas que protejan los datos personales.\n\n\nA la Argentina le sirven leyes que potencien el desarrollo y la innovaci√≥n, que promuevan el buen uso de la tecnolog√≠a, que garanticen el acceso y que protejan a quienes lo necesitan frente a los potenciales abusos.\nSi no existieran leyes para la aviaci√≥n, ninguna compa√±√≠a podr√≠a volar: el riesgo ser√≠a demasiado grande. Si no hubiera leyes de tr√°nsito, las calles ser√≠an un caos y los choques constantes. Regular no es prohibir. Regular no es poner trabas. Regular puede servir para organizar y potenciar el desarrollo.\nLa discusi√≥n sobre ‚Äúleyes de IA s√≠ / leyes de IA no‚Äù ya no va m√°s. Lo que Argentina necesita es una estrategia clara de modernizaci√≥n para no perder la oportunidad que ofrece la inteligencia artificial. En ese camino, la regulaci√≥n es una herramienta m√°s, no un obst√°culo.\n\nPublicado originalmente en √Åmbito\n\n\n\n\n\nTodas Pol√≠ticas P√∫blicas Regulaci√≥n Tecnolog√≠a Educaci√≥n Pol√≠tica Deepfakes Democracia Innovaci√≥n"
  },
  {
    "objectID": "posts/sturzenegger-argentina-no-necesita-ley-ia.html#regular-para-ordenar-no-para-frenar",
    "href": "posts/sturzenegger-argentina-no-necesita-ley-ia.html#regular-para-ordenar-no-para-frenar",
    "title": "Federico Sturzenegger tiene raz√≥n: Argentina no necesita una ley de inteligencia artificial",
    "section": "",
    "text": "A la Argentina le sirven leyes que potencien el desarrollo y la innovaci√≥n, que promuevan el buen uso de la tecnolog√≠a, que garanticen el acceso y que protejan a quienes lo necesitan frente a los potenciales abusos.\nSi no existieran leyes para la aviaci√≥n, ninguna compa√±√≠a podr√≠a volar: el riesgo ser√≠a demasiado grande. Si no hubiera leyes de tr√°nsito, las calles ser√≠an un caos y los choques constantes. Regular no es prohibir. Regular no es poner trabas. Regular puede servir para organizar y potenciar el desarrollo.\nLa discusi√≥n sobre ‚Äúleyes de IA s√≠ / leyes de IA no‚Äù ya no va m√°s. Lo que Argentina necesita es una estrategia clara de modernizaci√≥n para no perder la oportunidad que ofrece la inteligencia artificial. En ese camino, la regulaci√≥n es una herramienta m√°s, no un obst√°culo.\n\nPublicado originalmente en √Åmbito"
  },
  {
    "objectID": "posts/no-culpen-al-algoritmo.html",
    "href": "posts/no-culpen-al-algoritmo.html",
    "title": "No culpen al algoritmo: ¬øc√≥mo regular la inteligencia artificial en un mundo demasiado humano?",
    "section": "",
    "text": "En 2018, mientras en el Congreso se debat√≠a la despenalizaci√≥n del aborto, el gobierno de la provincia de Salta anunci√≥ un algoritmo que permit√≠a predecir embarazos adolescentes. Esta iniciativa fue recibida con amplias cr√≠ticas y gener√≥ much√≠simo rechazo por su visi√≥n discriminadora. M√°s aun, el repudio no se dio s√≥lo a nivel local: el algoritmo lleg√≥ a la revista WIRED y fue juzgado negativamente por investigadores de Cambridge. El sistema propuesto ¬´etiquetaba¬ª a adolescentes salte√±as seg√∫n su nivel de riesgo de embarazo. Fueron tan demoledoras las cr√≠ticas que no lleg√≥ a utilizarse y nunca se conoci√≥ cu√°les iban a ser los usos de esta predicci√≥n.\nEn 2022, el Ministerio de Educaci√≥n de Mendoza puso en funcionamiento un sistema de alerta temprana de trayectorias en riesgo (SAT), que permite predecir la interrupci√≥n de las trayectorias educativas de estudiantes secundarios. El SAT agiliza la identificaci√≥n de estudiantes en riesgo de deserci√≥n escolar y permite la intervenci√≥n temprana para evitar que se interrumpa su escolaridad. Varios actores, incluso Fundar, lo reconocen como un caso de √©xito de uso de datos para definici√≥n de pol√≠ticas p√∫blicas y de modelos predictivos con impacto social.\nSeg√∫n varios expertos, uno de los principales motivos de la interrupci√≥n de las trayectorias educativas es el embarazo adolescente.\nEstamos hablando del mismo algoritmo para los dos casos: ¬øpor qu√© motivos el sistema de predicci√≥n de embarazos es objeto de cr√≠tica casi un√°nime, y la predicci√≥n de interrupci√≥n educativa es reconocido como un caso de √©xito? ¬øPodemos entender esos motivos para proponer una regulaci√≥n clara de la IA que evite los usos estigmatizantes y fomente aquellos que potencien el desarrollo?\nEs que los casos de √©xito del uso de la IA ‚Äîo su contracara, los casos en los que el uso de la IA es percibida como una amenaza‚Äî no se explican por los algoritmos o modelos utilizados: se explican por los contextos e intencionalidades de uso.\n\n\nLos riesgos en el uso de la IA han sido ampliamente estudiados y suelen citarse para justificar la necesidad de una regulaci√≥n. Parte de estos riesgos derivan de los potenciales sesgos, estad√≠sticos, algor√≠tmicos, de entrenamiento, como los de las bases de datos usadas para alimentar estos sistemas. Otros riesgos provienen de las llamadas ‚Äúalucinaciones‚Äù: los sistemas de IA generativa responden prediciendo texto: incluso si no cuentan con la informaci√≥n solicitada, van a responder algo (dicho con menos tecnicismos: mandan fruta).\nTambi√©n existen otros riesgos vinculados al uso de los sistemas. Por ejemplo, la generaci√≥n de im√°genes, videos o sonidos para producir noticias falsas (fake news) y hacerlas circular por redes. Como ejemplo menos grave, la posibilidad de que se produzcan violaciones a los derechos de autor.\nAhora bien, no es lo mismo regular la IA que regular su uso. Tomemos como ejemplo los autos. Regular los autom√≥viles es obligar a que cuenten con airbags o cinturones de seguridad. Regular su uso es definir velocidades m√°ximas o exigir licencias de conducir. De forma an√°loga, m√°s importante que regular la IA es regular el uso de la IA, y el uso cambia en diferentes contextos y actividades: un sistema de IA en salud no puede ser tratado de la misma forma que en un juego de plataforma. Si bien en ambos casos existe el riesgo de filtraci√≥n de datos usados en el entrenamiento, los da√±os potenciales de una filtraci√≥n de datos sobre enfermedades o condiciones de salud es potencialmente mucho mayor que en el caso de un juego.\n\n\n\nEn Argentina existen numerosos proyectos de ley para regular la IA. Por lo general, la definici√≥n de IA usada en esas propuestas es tan laxa que, en su interpretaci√≥n m√°s literal, alcanza incluso al uso de planillas de c√°lculo como Excel.\nEn contraste, la regulaci√≥n europea, as√≠ como algunas √≥rdenes ejecutivas de Estados Unidos, establecen una l√≠nea divisoria entre modelos sencillos y avanzados, a partir del esfuerzo de poder de c√≥mputo necesario para entrenarlos. Es decir, la divisi√≥n est√° dada por la cantidad de operaciones necesarias para entrenar el modelo: si son m√°s de 10^24 FLOPS (operaciones de punto flotante) se habla de modelos avanzados, para los cuales se define un conjunto particular de normas.\nAmbas aproximaciones, la m√°s espec√≠fica y la m√°s general, resultan problem√°ticas. La toma de decisiones autom√°ticas no es exclusiva de la IA ni es algo nuevo en sistemas digitales. Los algoritmos con reglas fijas tambi√©n toman decisiones en forma determin√≠stica y regularlos no ser√≠a regular IA: ser√≠a regular sistemas inform√°ticos en general. Por otro lado, no sabemos si el l√≠mite de 10^24 es correcto, ya que resulta enormemente arbitrario y muy probablemente cambiar√° a medida que se desarrollen nuevas tecnolog√≠as. Los cambios que estamos experimentando con la IA se dan de forma mucho m√°s r√°pida que la velocidad en que cambia una regulaci√≥n.\nPero adem√°s, el impacto social de una tecnolog√≠a no necesariamente tiene que ver con su complejidad, algo que se vio en el caso de la Therac 25.\nLa Therac 25 era una m√°quina usada para tratamiento con radiaci√≥n. Debido a un error en su programaci√≥n, en determinadas situaciones liberaba una cantidad de radiaci√≥n que resultaba en √≥rdenes de magnitud mayores a las dosis prescriptas, causando lastimaduras. De hecho, hay casos documentados de muerte por exceso de radiaci√≥n luego del uso de la m√°quina. ¬øQu√© pas√≥ una vez que se descubri√≥ el error? La empresa que desarroll√≥ la Therac 25 se declar√≥ en quiebra y el programador demostr√≥ que hab√≠a respondido a los requerimientos: los requerimientos, por su parte, eran correctos, pero estaban escritos en un lenguaje poco com√∫n y el testeo fue realizado de acuerdo con ‚Äúlos est√°ndares de la √©poca‚Äù. En otras palabras, se produjo un error de enorme impacto sin que pudiera establecerse un responsable claro y sin que exista ¬´inteligencia artificial¬ª de por medio.\nDe este ejemplo se desprenden dos lecciones: primero, un marco regulatorio sin capacidades estatales de control y sin una autoridad de aplicaci√≥n que lo garantice sirve de poco; y segundo, el impacto social de una tecnolog√≠a tiene poco que ver con la complejidad del modelo o si es una IA o un sistema tradicional.\nUn camino alternativo es adaptar la regulaci√≥n de los algoritmos o modelos en funci√≥n del tipo de uso. As√≠, en casos como el de la Therac 25, de nada sirve regular la IA o la toma de decisiones autom√°ticas: lo que deber√≠a regularse es el uso de dispositivos m√©dicos que incorporan software. Este criterio podr√≠a llevarse a otras industrias y actividades: alimentos, salud, seguridad tienen normas espec√≠ficas que deber√°n ser ampliadas en algunos casos para considerar el uso de nuevas herramientas. En todos esos casos el objeto de la regulaci√≥n es el alimento, el tratamiento o la actividad. La regulaci√≥n de la herramienta reci√©n podr√≠a darse en un paso posterior y en funci√≥n de las especificidades del objeto.\nEn las discusiones sobre regulaci√≥n de la IA suele proponerse la validaci√≥n humana de las decisiones autom√°ticas generadas por un modelo o algoritmo (human in the loop) como condici√≥n para evitar potenciales errores o riesgos: se tratar√≠a entonces de decisiones tomadas por una persona asesorada por una IA. Sin embargo, si bien es clave que exista un ser humano que avale y tome la responsabilidad sobre el uso de esta herramienta, eso no resulta suficiente. El problema, m√°s profundo, es que existen sesgos cognitivos y situaciones sociales que suelen llevar a las personas a aceptar como v√°lidas las recomendaciones de los sistemas de IA, por falta de un criterio cr√≠tico. Por un lado, debido a la existencia de fuertes incentivos para su aceptaci√≥n y desincentivos a desafiarlas, o sencillamente porque ocupan toda la atenci√≥n del humano.\nUn ejemplo de los incentivos es el caso de COMPAS, un sistema que asesoraba a jueces a partir de la estimaci√≥n del riesgo de reincidencia en personas condenadas bajo la ley penal cuyas recomendaciones fueron aceptadas sin cambios en un alt√≠simo porcentaje. Un ejemplo de la manipulaci√≥n de la atenci√≥n se da en los algoritmos de recomendaci√≥n o selecci√≥n de contenido en redes sociales, que terminamos aceptando en forma pasiva para que elija qu√© tenemos que ver, como si fuera la √∫nica selecci√≥n de contenido posible. Las recomendaciones sin una verdadera revisi√≥n cr√≠tica terminan siendo imposiciones.\n\n\n\nLos tiempos de la innovaci√≥n tecnol√≥gica, de la competitividad empresarial y de los procesos regulatorios son distintos. Nos encontramos en una etapa inicial en la incorporaci√≥n de la IA en las actividades productivas y sociales. Si bien existen ya numerosos ejemplos de uso, dista de ser un fen√≥meno masivo. Incluso los estudios de impacto se√±alan que a√∫n es temprano para comprender claramente c√≥mo va a desenvolverse el uso de la IA.\nRegular una tecnolog√≠a en su etapa inicial puede ser problem√°tico, sobre todo porque no sabemos c√≥mo va a ser su despliegue. A su vez, las zonas grises no reguladas pueden resultar problem√°ticas: ya vemos en la pr√°ctica el impacto que el uso de la IA puede tener en la manipulaci√≥n de elecciones o la propagaci√≥n de noticias falsas.\nSi retomamos el ejemplo de los autos como referencia, estamos en una etapa similar al momento en que Gottlieb Daimler propon√≠a sus ‚Äúcarros de caballo con motor‚Äù. Se empezaban a discutir algunos riesgos (carros que iban a velocidades astron√≥micas de 20 km/h) y la conveniencia de estas m√°quinas frente a los caballos (mucho m√°s confiables), entre otras cosas. Proponer el uso de cinturones de seguridad en ese momento era impensable. Esto no quiere decir que no sea necesario tomar recaudos en actividades y usos espec√≠ficos, pero es fundamental tener en cuenta que nos encontramos en una etapa inicial.\nUn indicio claro de que se trata de un momento inicial es la disparidad entre las discusiones sobre la regulaci√≥n de la IA y la regulaci√≥n del uso de datos, al menos en nuestro pa√≠s. Si bien existen numerosas propuestas de regulaci√≥n de IA, la regulaci√≥n de datos personales y del uso de datos en el estado no tiene ning√∫n avance desde hace varios a√±os. Hay consenso en que la ley argentina de datos personales tiene muchos aspectos antiguos o que deben mejorarse. En particular, fue redactada antes de que aparezcan muchas innovaciones que cambiaron el panorama social con respecto a lo digital. Sin embargo, no se llegan a acuerdos en los proyectos de regulaci√≥n ni parece un tema prioritario en la agenda. La IA sin datos no existe: los desarrollos de IA s√≥lo son posibles mediante el uso de grandes cantidades de datos. Sin embargo, a√∫n est√° en discusi√≥n de qui√©n son esos datos, qui√©n y para qu√© puede usarlos, qu√© derechos tienen los ciudadanos sobre sus datos y qu√© datos puede usar el Estado en sus diferentes dependencias para ser m√°s eficiente ‚Äîy, a la par, qu√© responsabilidades genera este uso‚Äî. Es clave regular el uso de datos como un paso en el camino que lleve a regular la IA.\n\n\n\nUn paso previo a la regulaci√≥n de la IA es modernizar, modificar y renovar la Ley de Datos Personales, y establecer una normativa moderna para el intercambio y manipulaci√≥n de datos en el Estado y entre privados.\nUna regulaci√≥n para la IA debe ser pensada sobre su uso y no sobre la tecnolog√≠a. Regular los algoritmos no es la soluci√≥n. La discusi√≥n podr√≠a ordenarse en tres pasos:\n\nDefinir los principales escenarios de uso de la IA en el presente y para el corto y mediano plazo, de manera tal de bajar a tierra la discusi√≥n. Esto permite concentrarse en los escenarios que ya se conocen o vislumbran y no adelantar discusiones para casos a√∫n desconocidos.\nIdentificar y analizar riesgos potenciales en cada escenario, realizando el an√°lisis de riesgos con una matriz de probabilidad, impacto y mitigaci√≥n para cada uno de ellos.\nPara los escenarios de mayor riesgo, validar si la regulaci√≥n actual aplicable al escenario resulta suficiente o si se requiere mayor precisi√≥n. Los casos que no est√©n cubiertos son candidatos para contar con una extensi√≥n de la regulaci√≥n existente o una nueva propuesta regulatoria.\n\nDe esta validaci√≥n pueden surgir diferentes casos:\n\naquellos en los que la regulaci√≥n existente sea suficiente;\nlos que requieran alg√∫n ajuste en en su reglamentaci√≥n;\nlos que quedar√°n definidos a trav√©s de jurisprudencia y no necesariamente en nuevas leyes o reglamentos;\nalgunos que, adem√°s de requerir de acci√≥n inmediata, resultan de mayor complejidad, como pueden ser las noticias falsas y la manipulaci√≥n de las redes sociales.\n\nLos casos de noticias falsas generan tensi√≥n entre la necesidad de regularlos y la libertad de expresi√≥n, y deben ser analizados en forma particular considerando esa tensi√≥n. Esta es a√∫n una discusi√≥n abierta para la que no existen soluciones simples. Otros casos particulares deben ser tratados por dominio de aplicaci√≥n. El uso de IA en salud, educaci√≥n y seguridad debe ser analizado por expertos del dominio para los escenarios que se identifiquen. El uso de modelos avanzados en actividades recreativas o en an√°lisis t√©cnicos de ingenier√≠a no parecen ser casos relevantes en la actualidad a la hora de pensar regulaciones, lo que no quiere decir que a futuro no sea necesario avanzar en esa direcci√≥n.\nLos algoritmos no pueden tener responsabilidad: la responsabilidad del uso de IA debe ser asumida por alguien. Si el uso de IA, como el uso de cualquier herramienta, produce da√±os o tiene un impacto negativo, debe estar claramente definido el responsable.\nAvanzar muy r√°pido en regulaciones sin dar los pasos previos necesarios es tan riesgoso como no avanzar en absoluto.\n\nPublicado originalmente en Fundar\n\n\n\n\n\nTodas Pol√≠ticas P√∫blicas Regulaci√≥n Tecnolog√≠a Educaci√≥n Pol√≠tica Deepfakes Democracia Innovaci√≥n"
  },
  {
    "objectID": "posts/no-culpen-al-algoritmo.html#hacia-una-regulaci√≥n-de-la-ia",
    "href": "posts/no-culpen-al-algoritmo.html#hacia-una-regulaci√≥n-de-la-ia",
    "title": "No culpen al algoritmo: ¬øc√≥mo regular la inteligencia artificial en un mundo demasiado humano?",
    "section": "",
    "text": "Los riesgos en el uso de la IA han sido ampliamente estudiados y suelen citarse para justificar la necesidad de una regulaci√≥n. Parte de estos riesgos derivan de los potenciales sesgos, estad√≠sticos, algor√≠tmicos, de entrenamiento, como los de las bases de datos usadas para alimentar estos sistemas. Otros riesgos provienen de las llamadas ‚Äúalucinaciones‚Äù: los sistemas de IA generativa responden prediciendo texto: incluso si no cuentan con la informaci√≥n solicitada, van a responder algo (dicho con menos tecnicismos: mandan fruta).\nTambi√©n existen otros riesgos vinculados al uso de los sistemas. Por ejemplo, la generaci√≥n de im√°genes, videos o sonidos para producir noticias falsas (fake news) y hacerlas circular por redes. Como ejemplo menos grave, la posibilidad de que se produzcan violaciones a los derechos de autor.\nAhora bien, no es lo mismo regular la IA que regular su uso. Tomemos como ejemplo los autos. Regular los autom√≥viles es obligar a que cuenten con airbags o cinturones de seguridad. Regular su uso es definir velocidades m√°ximas o exigir licencias de conducir. De forma an√°loga, m√°s importante que regular la IA es regular el uso de la IA, y el uso cambia en diferentes contextos y actividades: un sistema de IA en salud no puede ser tratado de la misma forma que en un juego de plataforma. Si bien en ambos casos existe el riesgo de filtraci√≥n de datos usados en el entrenamiento, los da√±os potenciales de una filtraci√≥n de datos sobre enfermedades o condiciones de salud es potencialmente mucho mayor que en el caso de un juego."
  },
  {
    "objectID": "posts/no-culpen-al-algoritmo.html#de-qu√©-hablamos-cuando-hablamos-de-regular-el-uso-de-la-ia",
    "href": "posts/no-culpen-al-algoritmo.html#de-qu√©-hablamos-cuando-hablamos-de-regular-el-uso-de-la-ia",
    "title": "No culpen al algoritmo: ¬øc√≥mo regular la inteligencia artificial en un mundo demasiado humano?",
    "section": "",
    "text": "En Argentina existen numerosos proyectos de ley para regular la IA. Por lo general, la definici√≥n de IA usada en esas propuestas es tan laxa que, en su interpretaci√≥n m√°s literal, alcanza incluso al uso de planillas de c√°lculo como Excel.\nEn contraste, la regulaci√≥n europea, as√≠ como algunas √≥rdenes ejecutivas de Estados Unidos, establecen una l√≠nea divisoria entre modelos sencillos y avanzados, a partir del esfuerzo de poder de c√≥mputo necesario para entrenarlos. Es decir, la divisi√≥n est√° dada por la cantidad de operaciones necesarias para entrenar el modelo: si son m√°s de 10^24 FLOPS (operaciones de punto flotante) se habla de modelos avanzados, para los cuales se define un conjunto particular de normas.\nAmbas aproximaciones, la m√°s espec√≠fica y la m√°s general, resultan problem√°ticas. La toma de decisiones autom√°ticas no es exclusiva de la IA ni es algo nuevo en sistemas digitales. Los algoritmos con reglas fijas tambi√©n toman decisiones en forma determin√≠stica y regularlos no ser√≠a regular IA: ser√≠a regular sistemas inform√°ticos en general. Por otro lado, no sabemos si el l√≠mite de 10^24 es correcto, ya que resulta enormemente arbitrario y muy probablemente cambiar√° a medida que se desarrollen nuevas tecnolog√≠as. Los cambios que estamos experimentando con la IA se dan de forma mucho m√°s r√°pida que la velocidad en que cambia una regulaci√≥n.\nPero adem√°s, el impacto social de una tecnolog√≠a no necesariamente tiene que ver con su complejidad, algo que se vio en el caso de la Therac 25.\nLa Therac 25 era una m√°quina usada para tratamiento con radiaci√≥n. Debido a un error en su programaci√≥n, en determinadas situaciones liberaba una cantidad de radiaci√≥n que resultaba en √≥rdenes de magnitud mayores a las dosis prescriptas, causando lastimaduras. De hecho, hay casos documentados de muerte por exceso de radiaci√≥n luego del uso de la m√°quina. ¬øQu√© pas√≥ una vez que se descubri√≥ el error? La empresa que desarroll√≥ la Therac 25 se declar√≥ en quiebra y el programador demostr√≥ que hab√≠a respondido a los requerimientos: los requerimientos, por su parte, eran correctos, pero estaban escritos en un lenguaje poco com√∫n y el testeo fue realizado de acuerdo con ‚Äúlos est√°ndares de la √©poca‚Äù. En otras palabras, se produjo un error de enorme impacto sin que pudiera establecerse un responsable claro y sin que exista ¬´inteligencia artificial¬ª de por medio.\nDe este ejemplo se desprenden dos lecciones: primero, un marco regulatorio sin capacidades estatales de control y sin una autoridad de aplicaci√≥n que lo garantice sirve de poco; y segundo, el impacto social de una tecnolog√≠a tiene poco que ver con la complejidad del modelo o si es una IA o un sistema tradicional.\nUn camino alternativo es adaptar la regulaci√≥n de los algoritmos o modelos en funci√≥n del tipo de uso. As√≠, en casos como el de la Therac 25, de nada sirve regular la IA o la toma de decisiones autom√°ticas: lo que deber√≠a regularse es el uso de dispositivos m√©dicos que incorporan software. Este criterio podr√≠a llevarse a otras industrias y actividades: alimentos, salud, seguridad tienen normas espec√≠ficas que deber√°n ser ampliadas en algunos casos para considerar el uso de nuevas herramientas. En todos esos casos el objeto de la regulaci√≥n es el alimento, el tratamiento o la actividad. La regulaci√≥n de la herramienta reci√©n podr√≠a darse en un paso posterior y en funci√≥n de las especificidades del objeto.\nEn las discusiones sobre regulaci√≥n de la IA suele proponerse la validaci√≥n humana de las decisiones autom√°ticas generadas por un modelo o algoritmo (human in the loop) como condici√≥n para evitar potenciales errores o riesgos: se tratar√≠a entonces de decisiones tomadas por una persona asesorada por una IA. Sin embargo, si bien es clave que exista un ser humano que avale y tome la responsabilidad sobre el uso de esta herramienta, eso no resulta suficiente. El problema, m√°s profundo, es que existen sesgos cognitivos y situaciones sociales que suelen llevar a las personas a aceptar como v√°lidas las recomendaciones de los sistemas de IA, por falta de un criterio cr√≠tico. Por un lado, debido a la existencia de fuertes incentivos para su aceptaci√≥n y desincentivos a desafiarlas, o sencillamente porque ocupan toda la atenci√≥n del humano.\nUn ejemplo de los incentivos es el caso de COMPAS, un sistema que asesoraba a jueces a partir de la estimaci√≥n del riesgo de reincidencia en personas condenadas bajo la ley penal cuyas recomendaciones fueron aceptadas sin cambios en un alt√≠simo porcentaje. Un ejemplo de la manipulaci√≥n de la atenci√≥n se da en los algoritmos de recomendaci√≥n o selecci√≥n de contenido en redes sociales, que terminamos aceptando en forma pasiva para que elija qu√© tenemos que ver, como si fuera la √∫nica selecci√≥n de contenido posible. Las recomendaciones sin una verdadera revisi√≥n cr√≠tica terminan siendo imposiciones."
  },
  {
    "objectID": "posts/no-culpen-al-algoritmo.html#en-qu√©-etapa-estamos",
    "href": "posts/no-culpen-al-algoritmo.html#en-qu√©-etapa-estamos",
    "title": "No culpen al algoritmo: ¬øc√≥mo regular la inteligencia artificial en un mundo demasiado humano?",
    "section": "",
    "text": "Los tiempos de la innovaci√≥n tecnol√≥gica, de la competitividad empresarial y de los procesos regulatorios son distintos. Nos encontramos en una etapa inicial en la incorporaci√≥n de la IA en las actividades productivas y sociales. Si bien existen ya numerosos ejemplos de uso, dista de ser un fen√≥meno masivo. Incluso los estudios de impacto se√±alan que a√∫n es temprano para comprender claramente c√≥mo va a desenvolverse el uso de la IA.\nRegular una tecnolog√≠a en su etapa inicial puede ser problem√°tico, sobre todo porque no sabemos c√≥mo va a ser su despliegue. A su vez, las zonas grises no reguladas pueden resultar problem√°ticas: ya vemos en la pr√°ctica el impacto que el uso de la IA puede tener en la manipulaci√≥n de elecciones o la propagaci√≥n de noticias falsas.\nSi retomamos el ejemplo de los autos como referencia, estamos en una etapa similar al momento en que Gottlieb Daimler propon√≠a sus ‚Äúcarros de caballo con motor‚Äù. Se empezaban a discutir algunos riesgos (carros que iban a velocidades astron√≥micas de 20 km/h) y la conveniencia de estas m√°quinas frente a los caballos (mucho m√°s confiables), entre otras cosas. Proponer el uso de cinturones de seguridad en ese momento era impensable. Esto no quiere decir que no sea necesario tomar recaudos en actividades y usos espec√≠ficos, pero es fundamental tener en cuenta que nos encontramos en una etapa inicial.\nUn indicio claro de que se trata de un momento inicial es la disparidad entre las discusiones sobre la regulaci√≥n de la IA y la regulaci√≥n del uso de datos, al menos en nuestro pa√≠s. Si bien existen numerosas propuestas de regulaci√≥n de IA, la regulaci√≥n de datos personales y del uso de datos en el estado no tiene ning√∫n avance desde hace varios a√±os. Hay consenso en que la ley argentina de datos personales tiene muchos aspectos antiguos o que deben mejorarse. En particular, fue redactada antes de que aparezcan muchas innovaciones que cambiaron el panorama social con respecto a lo digital. Sin embargo, no se llegan a acuerdos en los proyectos de regulaci√≥n ni parece un tema prioritario en la agenda. La IA sin datos no existe: los desarrollos de IA s√≥lo son posibles mediante el uso de grandes cantidades de datos. Sin embargo, a√∫n est√° en discusi√≥n de qui√©n son esos datos, qui√©n y para qu√© puede usarlos, qu√© derechos tienen los ciudadanos sobre sus datos y qu√© datos puede usar el Estado en sus diferentes dependencias para ser m√°s eficiente ‚Äîy, a la par, qu√© responsabilidades genera este uso‚Äî. Es clave regular el uso de datos como un paso en el camino que lleve a regular la IA."
  },
  {
    "objectID": "posts/no-culpen-al-algoritmo.html#una-propuesta",
    "href": "posts/no-culpen-al-algoritmo.html#una-propuesta",
    "title": "No culpen al algoritmo: ¬øc√≥mo regular la inteligencia artificial en un mundo demasiado humano?",
    "section": "",
    "text": "Un paso previo a la regulaci√≥n de la IA es modernizar, modificar y renovar la Ley de Datos Personales, y establecer una normativa moderna para el intercambio y manipulaci√≥n de datos en el Estado y entre privados.\nUna regulaci√≥n para la IA debe ser pensada sobre su uso y no sobre la tecnolog√≠a. Regular los algoritmos no es la soluci√≥n. La discusi√≥n podr√≠a ordenarse en tres pasos:\n\nDefinir los principales escenarios de uso de la IA en el presente y para el corto y mediano plazo, de manera tal de bajar a tierra la discusi√≥n. Esto permite concentrarse en los escenarios que ya se conocen o vislumbran y no adelantar discusiones para casos a√∫n desconocidos.\nIdentificar y analizar riesgos potenciales en cada escenario, realizando el an√°lisis de riesgos con una matriz de probabilidad, impacto y mitigaci√≥n para cada uno de ellos.\nPara los escenarios de mayor riesgo, validar si la regulaci√≥n actual aplicable al escenario resulta suficiente o si se requiere mayor precisi√≥n. Los casos que no est√©n cubiertos son candidatos para contar con una extensi√≥n de la regulaci√≥n existente o una nueva propuesta regulatoria.\n\nDe esta validaci√≥n pueden surgir diferentes casos:\n\naquellos en los que la regulaci√≥n existente sea suficiente;\nlos que requieran alg√∫n ajuste en en su reglamentaci√≥n;\nlos que quedar√°n definidos a trav√©s de jurisprudencia y no necesariamente en nuevas leyes o reglamentos;\nalgunos que, adem√°s de requerir de acci√≥n inmediata, resultan de mayor complejidad, como pueden ser las noticias falsas y la manipulaci√≥n de las redes sociales.\n\nLos casos de noticias falsas generan tensi√≥n entre la necesidad de regularlos y la libertad de expresi√≥n, y deben ser analizados en forma particular considerando esa tensi√≥n. Esta es a√∫n una discusi√≥n abierta para la que no existen soluciones simples. Otros casos particulares deben ser tratados por dominio de aplicaci√≥n. El uso de IA en salud, educaci√≥n y seguridad debe ser analizado por expertos del dominio para los escenarios que se identifiquen. El uso de modelos avanzados en actividades recreativas o en an√°lisis t√©cnicos de ingenier√≠a no parecen ser casos relevantes en la actualidad a la hora de pensar regulaciones, lo que no quiere decir que a futuro no sea necesario avanzar en esa direcci√≥n.\nLos algoritmos no pueden tener responsabilidad: la responsabilidad del uso de IA debe ser asumida por alguien. Si el uso de IA, como el uso de cualquier herramienta, produce da√±os o tiene un impacto negativo, debe estar claramente definido el responsable.\nAvanzar muy r√°pido en regulaciones sin dar los pasos previos necesarios es tan riesgoso como no avanzar en absoluto.\n\nPublicado originalmente en Fundar"
  },
  {
    "objectID": "posts/deepfakes-campanas-sucias.html",
    "href": "posts/deepfakes-campanas-sucias.html",
    "title": "Deepfakes, campa√±as sucias y un dec√°logo que parece s√°tira, pero denuncia algo muy real",
    "section": "",
    "text": "El a√±o pasado hubo al menos tres casos en que un alumno de secundaria public√≥ videos √≠ntimos de sus compa√±eras. El tema trascendi√≥ porque, en todos los casos,¬†no eran exactamente ellas.¬†Eran videos editados usando inteligencia artificial (IA)¬†llamados¬†deepfakes. Esto no lo hace gracioso ni menos grave: las chicas fueron efectivamente muy expuestas y agredidas, y aunque r√°pidamente se supo que eran¬†fake, no quita que sea un problema serio que esos videos sigan dando vueltas por internet.\nEste es un problema serio. El gobierno de Trump, al que nadie puede acusar de¬†woke¬†o progresista, impuls√≥ una ley llamada ‚ÄúTake It Down Act‚Äù (Ley Elim√≠nalo, en espa√±ol): desde el 19 de mayo de 2025¬†es delito federal en Estado Unidos publicar a sabiendas¬†representaciones visuales √≠ntimas de personas sin su consentimiento. Esto incluye im√°genes reales y¬†deepfakes, y tiene implicancias directas sobre las formas de hacer campa√±as pol√≠ticas.\nEn ese sentido, es imposible no mencionar lo que sucedi√≥ en las √∫ltimas elecciones de la Ciudad de Buenos Aires: circul√≥ un video de Mauricio Macri, en el cual el expresidente llamaba a votar a Manuel Adorni en vez de a Silvia Lospennato. Un ojo entrenado se daba cuenta bastante r√°pido de que era un video falso hecho con IA, un¬†deepfake.¬†El PRO cree que este video puede haber cambiado alg√∫n porcentaje de las elecciones¬†y lo denunciaron en la justicia electoral. Seg√∫n Macri, ‚Äúesta acci√≥n tramposa demuestra un profundo desprecio por las reglas electorales y, en el fondo, por la democracia misma‚Äù.\nEn Fundar venimos trabajando desde hace a√±os sobre el uso de IA y sus riesgos. Alertamos sobre su potencial uso para manipular, en particular en contexto de elecciones. Como no logramos que esto sea tomado en serio, recordamos el viejo truco de la psicolog√≠a inversa. Aqu√≠ va un cambio de foco:¬†un dec√°logo de recomendaciones para el uso de IA y¬†deepfakes¬†en campa√±as. No somos una organizaci√≥n partidaria, pueden usarlo todos por igual.\nDec√°logo de recomendaciones para una campa√±a con IA\n1.¬†Viralizar primero, (no) chequear despu√©s\nUsar IA para realizar videos o im√°genes de tu enemigo en una situaci√≥n rid√≠cula o humillante. Hemos visto a Putin llorando, a Biden durmiendo, y algunas m√°s inocentes como el Papa Francisco con campera, entre otros. El truco es viralizarlas r√°pido mediante la Red (ver regla 8): la imagen llega r√°pido, la desmentida toma tiempo. Nunca usar t√©rminos como opositor o contrincante, siempre llamarlo enemigo.\n2.¬†¬°Escuch√° el audio que me mand√≥!\nPod√©s usar IA para generar audios con la voz del enemigo, y hacerlos pasar como audios de WhatsApp. Un mensaje en que el enemigo confiesa haber roto una ley nacional, o mucho peor: confiesa no ba√±arse. Reenviarlo a la mayor cantidad posible de grupos de consorcio, club, o padres de la escuela.\n3.¬†Si el periodista dice que es¬†deepfake, hacerle un¬†deepfake¬†al periodista\n√çntimamente relacionada con la 1. Para que esto funcione bien, hay que bajarle el precio al periodismo serio, que puede desmitificar e identificar¬†fakes. Hay que montarse sobre el valor de las redes, donde todo vale, y circular¬†deepfakes¬†de estos nuevos enemigos. Si ellos protestan, burlarse por llorones. Si usan este Dec√°logo, tratarlos de falsos y mentirosos.\n4.¬†Un apodo duele m√°s que mil palabras\nUsar IA para combinar palabras que den apodos gracios√≠simos, hilarantes, de esos que no escuch√°s desde quinto grado. El truco es tirarle al chat diez instituciones que funcionen bien y que tu partido detesta, diez nombres de nuevos enemigos inventados, y pedirle que los combine. Estos apodos se viralizan f√°cilmente y permiten referirse al enemigo sin darle dimensi√≥n humana. Jam√°s reconocer valor alguno al enemigo.\n5.¬†Jugar a sus debilidades\nHay que estar atento a todas las fotos del enemigo. Por ejemplo, circula una imagen del enemigo y algo en su mesa parece, presuntamente, ser droga. La gente en la Red comienza a hablar de eso. Instant√°neamente, hay que pedir a la IA m√°s im√°genes que pongan de relieve esa presunta droga. Unos videos de Macron, Merz y Starmer en un tren a Kiev mostraban un pa√±uelo sobre la mesa. Poco despu√©s, con algo de ayuda, los vimos bailar, drogarse y tirar polvo blanco por todos lados. Esto se viraliza r√°pido, es clave mezclar IA con la realidad.\n6.¬†Relato IA mata mandato\nNo tener plataforma ni plan de gobierno: usar IA para personalizar propuestas considerando solo preocupaciones y miedos de cada persona. Lo √∫nico importante es borrar las marcas del chat, aunque, en realidad, a nadie le importa y hoy ya es org√°nico leer en medio de un texto ‚Äú¬°Qu√© buena idea! Ah√≠ te van 10 opciones de medidas falsas que podr√°n atraer a tu electorado‚Äù. Por ejemplo, si sabemos que una madre est√° preocupada por la seguridad de su hijo que viaja solo al colegio, hablarle de robots polic√≠as que le dan la mano y lo acompa√±an. Al ciudadano que viaja muchas horas diarias, mostrarle avances de nuevas l√≠neas de subte ficticias con im√°genes generadas por IA. No proponer, solo apuntar al miedo y al hartazgo con mensajes lo m√°s personalizados que la IA nos permita.\n7.¬†Agrega m√∫sculos y mand√≠bula, quita papada a esta foto\nSi crees que tu imagen no es lo suficientemente agresiva para enfrentarte a tus muchos enemigos, que est√°n por todos lados, pedirle al chat que altere tus fotos a piacere. Si muchos de tus amigos de la Red (ver 8) lo replican, empieza a ser verdad. Hoy somos en gran parte nuestros avatares, vos tambi√©n pod√©s tener m√∫sculos y no tener papada.\n8.¬†La Red\nArmar una red. Todo esto debe ser hecho desde cuentas con seud√≥nimos, replicadas por cuentas robot, militantes o tuiteros pagos. Mientras m√°s ani√±ados los nombres mejor. La estructura de la red debe planificarse para que cualquier publicaci√≥n pase por varios replicantes. La Red debe ser multiplataforma y controlada desde la Oficina Central.\n9.¬†Amigos de la Red ‚Äì Asociaci√≥n Heterog√©nea\nLa red debe tener una capa de cuentas de influencers conocidos, con el rol de potenciar y ser hubs de comunicaci√≥n. Pueden ser cosplayers, jugadores de Age of Empires u otros famosos. La estructura de la Red no es √∫nica, pero el orden en que se publica y la velocidad de publicaci√≥n son relevantes.\n10.¬†No seas as√≠, era un chiste nom√°s\nSi se descubre algo de todo esto, echar la culpa a las cuentas con seud√≥nimos o de autores desconocidos o decir que todo es una joda. Total, regulaci√≥n no hay.\nSi prefieren como nosotros un clima de elecciones distinto, donde estas cosas no sucedan o al menos no sean bien vistas,¬†invitemos a toda la clase pol√≠tica a consensuar reglas, en forma de regulaci√≥n o al menos acuerdos.¬†Cuando uno ve un video √≠ntimo con su cara circulando por internet, se da cuenta de que no siempre usar la IA produce resultados divertidos. Tampoco cuando se trata de la democracia.\n\nPublicado originalmente en TN\n\n\n\n\nTodas Pol√≠ticas P√∫blicas Regulaci√≥n Tecnolog√≠a Educaci√≥n Pol√≠tica Deepfakes Democracia Innovaci√≥n"
  },
  {
    "objectID": "posts/ia-sin-ciencia-ficcion.html",
    "href": "posts/ia-sin-ciencia-ficcion.html",
    "title": "Inteligencia artificial sin ciencia ficci√≥n: m√°s all√° de los chatbots, hay mucho por hacer",
    "section": "",
    "text": "M√°s que preocuparnos por frenar el ascenso inminente y universal de la IA, en Argentina la principal preocupaci√≥n deber√≠a ser su baja implementaci√≥n en las empresas y en particular en las pymes.\nLa irrupci√≥n de la IA generativa en 2022 dispar√≥ especulaciones m√°s cercanas a la ciencia ficci√≥n que a la realidad productiva. Nos invaden reels que alarman sobre la inminencia de robots en toda empresa y hogar de familia. Nos dicen que no hay vuelta atr√°s. Que ChatGPT es m√°s inteligente que todos nosotros y, por ende, nos reemplazar√° en todo lo que pueda ser automatizado (ya que¬†todo es automatizable). Pero, ¬ønos sirve esta perspectiva alarmista?\nEl perfeccionamiento exponencial de los LLM ‚Äîlarge language models¬†o modelos extensos de lenguaje‚Äî o, en su versi√≥n m√°s conocida, chatbots como¬†Chat GPT, Gemini, Claude o Copilot, despert√≥ en el mundo fascinaci√≥n y temor por igual.\nLa carrera entre grandes tecnol√≥gicas por la construcci√≥n del LLM m√°s inteligente en los √∫ltimos tres a√±os sediment√≥ una certeza: pronto alcanzaremos la¬†AGI. Estas tres siglas significan¬†artificial general intelligence¬†‚Äîo IA general‚Äî, tambi√©n nombrada como ‚Äúsuperinteligencia‚Äù. Estos dos conceptos representan aquel momento hipot√©tico en donde la IA superar√≠a a la inteligencia humana en todos los √°mbitos. O sea, un futuro en donde la IA¬†revise formularios, realice traducciones, redacte regulaciones o dise√±e f√°rmacos¬†mejor que cualquier ser humano y de manera aut√≥noma. Recientemente el progreso en datos, computaci√≥n y modelos adelantaron las proyecciones sobre la conquista de la AGI a dentro de 10, 5 y 2 a√±os. Seg√∫n Sam Altman, en OpenAI ya saben c√≥mo construirla. Expertos y empresarios en todo el mundo llamaron a detener los grandes desarrollos de la IA, hasta asegurar que estos est√©n alineados con ‚Äúvalores humanos‚Äù.\nEs important√≠simo que se den esos debates. Existen riesgos √©ticos, laborales y de seguridad reales que las pol√≠ticas y regulaciones tienen que atender.¬†Pero Argentina no es Silicon Valley.¬†M√°s que preocuparnos por frenar el ascenso inminente y universal de la IA, en Argentina la principal preocupaci√≥n deber√≠a ser¬†su baja implementaci√≥n.\nEs cierto que algunos sectores como la programaci√≥n, el dise√±o o la publicidad est√°n avanzando r√°pido, y es l√≥gico que eso contribuya a una sensaci√≥n de adopci√≥n generalizada. Es verdad que la IA hace im√°genes estilo Ghibli espectaculares y que con Veo-3 ya no podemos distinguir entre un video real y uno artificial. Pero, puesto en perspectiva, la difusi√≥n de esta tecnolog√≠a en el sector productivo todav√≠a es baja. Seg√∫n un estudio del BID, en 2023,¬†s√≥lo el 14% de las PyMEs en Argentina implementaron alg√∫n tipo de IA en sus procesos productivos¬†(aunque probablemente esa cifra ya sea m√°s alta hoy y m√°s a√∫n en empresas grandes).\nLa preocupaci√≥n por el surgimiento de un neoludismo local resulta exagerada porque tampoco es que haya tantas m√°quinas para romper. No es que el debate sobre el alineamiento humano de las potenciales capacidades de la IA no sea importante ni deba existir. Lo es. Pero para que estas preocupaciones se traduzcan en regulaciones concretas, primero tiene que existir un sujeto susceptible de ser regulado.\nPara salir de una discusi√≥n lejana a la realidad productiva nacional es necesario desmitificar un primer supuesto del debate. La IA es mucho m√°s que Chat GPT y los LLM son mucho m√°s que chatbots. El problema de reducir a la IA a un chat es que se corre el peligro de¬†alejar¬†a potenciales adoptantes de su uso. Es dif√≠cil pensar estrategias de implementaci√≥n de la IA si la √∫nica forma de intervenci√≥n en los procesos productivos de todas las cadenas de valor de cada vertical sectorial es un chatbot. La IA como tecnolog√≠a de prop√≥sito general abarca muchas m√°s t√©cnicas.\nEstas otras t√©cnicas son, de hecho, las que mayormente est√°n siendo desarrolladas e implementadas en Argentina.\nEn el¬†agro¬†se est√°n utilizando drones e im√°genes satelitales combinadas con t√©cnicas como visi√≥n por computadora y algoritmos cl√°sicos de aprendizaje autom√°tico para desarrollar soluciones que van desde el conteo de plantas, la detecci√≥n de plagas o el monitoreo y seguimiento del ganado.\nEl sector de la¬†energ√≠a¬†utiliza realidad virtual y aumentada para la formaci√≥n de trabajadores en entornos controlados y algoritmos de predicci√≥n del rendimiento y de posibles errores en la perforaci√≥n de pozos.\nEn el sector de la¬†salud¬†se desarrollaron modelos con deep learning para analizar lesiones y algoritmos de clasificaci√≥n para el an√°lisis de estudios mamogr√°ficos y de t√≥rax.\nUna cantidad significativa de estos casos de aplicaci√≥n surgieron no tanto de la licencia de modelos desarrollados en otros pa√≠ses, sino m√°s bien debido a la colaboraci√≥n entre empresas tradicionales con las distintas universidades e institutos de investigaci√≥n cient√≠fica p√∫blicas (como el INTA), y con las prol√≠ficas startups de IA argentinas¬†(agtechs, healthtecs, biotechs, climate techs,¬†entre otras) y empresas tecnol√≥gicas nacionales proveedoras de software y servicios inform√°ticos.\nEs necesario traer al centro de la discusi√≥n la variedad de casos de implementaci√≥n y sincerarnos acerca del¬†atraso¬†en la adopci√≥n tecnol√≥gica nacional: este cambio de perspectiva nos aleja de debates est√©riles sobre las promesas y amenazas grandilocuentes de la IA. Salir de esta par√°lisis, al mismo tiempo, nos permite pensar c√≥mo podemos y de qu√© manera queremos insertar la IA en el entramado productivo nacional.\nUna estrategia nacional¬†en clave desarrollista e inclusiva¬†tiene que ser llevada a cabo con acciones concretas que promuevan la implementaci√≥n de la IA en los procesos productivos. Acciones como pol√≠ticas de transferencia entre el sistema cient√≠fico tecnol√≥gico nacional y el sector productivo (que estuvieron bien direccionadas en iniciativas como el CAMIA o el pr√©stamo del BID al MINCyT para el desarrollo de aplicaciones de IA en sectores exportadores, pero quedaron finalmente truncas) o pol√≠ticas de formaci√≥n profesional que contemplen nuevas competencias laborales para el uso de IA en distintas ocupaciones. Estas acciones podr√≠an ser integradas por un centro que funcione como un¬†‚ÄúINTA de la IA‚Äù.¬†Un centro que integre distintas estrategias para atacar las barreras de implementaci√≥n de la IA en las empresas, las asista en oportunidades concretas de aplicaci√≥n y las ayude a integrar esta tecnolog√≠a de manera justa y democr√°tica en los lugares de trabajo.\nEl problema de las proyecciones sobre la completa e inminente automatizaci√≥n es que obvian la brecha entre los prototipos californianos y la adopci√≥n real de estas tecnolog√≠as en los sectores productivos. La explosi√≥n de productividad prometida por la IA no llegar√°¬†mientras la microempresa de comercio minorista en el NOA o la mediana empresa de autopartes de C√≥rdoba asocien la IA a Elon Musk y a Chat GPT.\nEn cambio, el aumento de la productividad y del desarrollo vendr√°n de la mano de un abordaje local de la IA ‚Äîcon menos promesas y amenazas‚Äì y con t√©cnicas de IA menos populares ‚Äìm√°s all√° de los LLM‚Äî. Para ser el tercer hub de IA en el mundo primero tenemos que dejar la ciencia ficci√≥n al territorio del cine y la literatura: el futuro productivo de nuestro pa√≠s requiere de otro tipo de imaginaci√≥n.\n\nPublicado originalmente en Clar√≠n\n\n\n\n\nTodas Pol√≠ticas P√∫blicas Regulaci√≥n Tecnolog√≠a Educaci√≥n Pol√≠tica Deepfakes Democracia Innovaci√≥n"
  },
  {
    "objectID": "PREVIEW_INSTRUCTIONS.html",
    "href": "PREVIEW_INSTRUCTIONS.html",
    "title": "Instrucciones para Preview del Sitio",
    "section": "",
    "text": "‚úÖ Branch redesign-nadia creado con todos los cambios ‚úÖ Cambios commiteados\n\n\n\n\n\n# Descargar e instalar Quarto\ncurl -LO https://quarto.org/download/latest/quarto-linux-amd64.deb\nsudo dpkg -i quarto-linux-amd64.deb\n\n# Renderizar el sitio\nquarto render\n\n# Iniciar servidor de preview (se abrir√° en http://localhost:4200)\nquarto preview\n\n\n\nSi tienes GitHub Actions configurado, puedes hacer push del branch y GitHub Pages mostrar√° autom√°ticamente el preview.\ngit push origin redesign-nadia\nLuego ve a: https://[tu-usuario].github.io/cepe-fundar.github.io/ (si est√° configurado)\n\n\n\nSi ya tienes archivos renderizados en docs/:\ncd docs\npython3 -m http.server 8000\nLuego abre: http://localhost:8000\n\n\n\n\nLos archivos en docs/ son de una renderizaci√≥n anterior. Necesitas ejecutar quarto render para ver los nuevos cambios."
  },
  {
    "objectID": "PREVIEW_INSTRUCTIONS.html#estado-actual",
    "href": "PREVIEW_INSTRUCTIONS.html#estado-actual",
    "title": "Instrucciones para Preview del Sitio",
    "section": "",
    "text": "‚úÖ Branch redesign-nadia creado con todos los cambios ‚úÖ Cambios commiteados"
  },
  {
    "objectID": "PREVIEW_INSTRUCTIONS.html#para-hacer-preview-del-sitio",
    "href": "PREVIEW_INSTRUCTIONS.html#para-hacer-preview-del-sitio",
    "title": "Instrucciones para Preview del Sitio",
    "section": "",
    "text": "# Descargar e instalar Quarto\ncurl -LO https://quarto.org/download/latest/quarto-linux-amd64.deb\nsudo dpkg -i quarto-linux-amd64.deb\n\n# Renderizar el sitio\nquarto render\n\n# Iniciar servidor de preview (se abrir√° en http://localhost:4200)\nquarto preview\n\n\n\nSi tienes GitHub Actions configurado, puedes hacer push del branch y GitHub Pages mostrar√° autom√°ticamente el preview.\ngit push origin redesign-nadia\nLuego ve a: https://[tu-usuario].github.io/cepe-fundar.github.io/ (si est√° configurado)\n\n\n\nSi ya tienes archivos renderizados en docs/:\ncd docs\npython3 -m http.server 8000\nLuego abre: http://localhost:8000"
  },
  {
    "objectID": "PREVIEW_INSTRUCTIONS.html#nota",
    "href": "PREVIEW_INSTRUCTIONS.html#nota",
    "title": "Instrucciones para Preview del Sitio",
    "section": "",
    "text": "Los archivos en docs/ son de una renderizaci√≥n anterior. Necesitas ejecutar quarto render para ver los nuevos cambios."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Manifiesto",
    "section": "",
    "text": "La inteligencia artificial ya est√° transformando nuestra econom√≠a: se integra en el agro, la salud, la industria, los servicios y la educaci√≥n. Tiene potencial para aumentar la productividad y abrir nuevas posibilidades, pero tambi√©n puede profundizar las desigualdades existentes y favorecer la concentraci√≥n de poder. El impacto futuro de la IA depende de las decisiones de pol√≠tica p√∫blica que tomemos hoy: c√≥mo se adopta, con qu√© regulaci√≥n, con qu√© prop√≥sito y en qu√© condiciones.\nPara que esta tecnolog√≠a sea un trampol√≠n real de desarrollo, se requiere estabilidad macroecon√≥mica, inversi√≥n sostenida, infraestructura digital, I+D, recursos humanos capacitados, y una estrategia de adopci√≥n con mirada de largo plazo. En contextos de volatilidad o fragmentaci√≥n institucional, la IA tiende a profundizar brechas en lugar de cerrarlas. La promesa de la IA sin esas condiciones es una promesa sin sost√©n.\nEl despliegue responsable de la IA en Argentina debe articular cinco ejes: trabajo y distribuci√≥n del ingreso; productividad y cuellos de botella; educaci√≥n y habilidades humanas; regulaci√≥n inteligente; y gobernanza estatal y regional.\nIA, desarrollo y trabajo: instituciones para una adopci√≥n inclusiva. La IA puede aumentar la productividad, pero no es una varita m√°gica. En econom√≠as fr√°giles, desiguales y con baja digitalizaci√≥n, sus beneficios no est√°n garantizados. De hecho, la adopci√≥n heterog√©nea, espasm√≥dica y segmentada puede agravar las brechas tecnol√≥gicas entre sectores y regiones.\nSi queremos que la IA se convierta en un vector de desarrollo inclusivo, se necesitan pol√≠ticas activas que promuevan la integraci√≥n de la IA a nuestras cadenas productivas: apoyo a la adopci√≥n tecnol√≥gica en PyMEs, difusi√≥n de buenas pr√°cticas, identificaci√≥n y superaci√≥n de cuellos de botella. Sin infraestructura, talento ni estabilidad macro, la IA no transforma: segrega.\nLa IA no s√≥lo cambia c√≥mo trabajamos. Cambia qu√© tareas existen y cu√°les desaparecen. La naturaleza y el alcance de esta transformaci√≥n a√∫n son inciertos. Pero s√≠ sabemos que, a diferencia de olas tecnol√≥gicas anteriores, la IA automatiza tambi√©n tareas cognitivas calificadas. El futuro del trabajo est√° en las actividades que la IA no puede hacer: creatividad, pensamiento cr√≠tico, cuidado, juicio √©tico.\nLa transici√≥n debe acompa√±arse con pol√≠ticas activas de formaci√≥n profesional, asistencia a PyMEs para reorganizar tareas y mesas de di√°logo entre Estado, empresas y trabajadores. En su ausencia, corremos el riesgo que la IA ampl√≠e desigualdades. Con las pol√≠ticas adecuadas, la IA puede convertirse en una herramienta de productividad compartida e inclusi√≥n social.\nIA y educaci√≥n: pensar cr√≠ticamente con la tecnolog√≠a. La IA desaf√≠a a la escuela y a la universidad. No alcanza con ense√±ar a usar herramientas: hay que ense√±ar a pensar con ellas, sin dejar de pensar por uno mismo. La educaci√≥n debe priorizar habilidades humanas que complementan a la IA: criterio, juicio, pensamiento cr√≠tico, creatividad.\nIntegrar la IA a las aulas no significa reemplazar la ense√±anza: significa acompa√±ar su uso con gu√≠a docente, evitar la utilizaci√≥n mec√°nica que atrofia el aprendizaje y redise√±ar el curr√≠culo para una realidad donde la IA es parte del entorno cognitivo. Hay que preparar a las personas para trabajar con la IA, no competir contra ella.\nIA y regulaci√≥n: medianeras para el desarrollo responsable. Las regulaciones no deben frenar la innovaci√≥n, pero tampoco pueden ausentarse. Sin reglas claras, la IA amplifica riesgos: opacidad algor√≠tmica, manipulaci√≥n de la opini√≥n p√∫blica, sesgos en decisiones sensibles y captura de mercados.\nNecesitamos una regulaci√≥n basada en usos y proporcional al riesgo, con principios de transparencia, rendici√≥n de cuentas y trazabilidad. Quienes dise√±an y operan sistemas de IA deben asumir responsabilidad por sus efectos. Tambi√©n es necesario evitar la concentraci√≥n del poder tecnol√≥gico en unas pocas plataformas globales. Fomentar la competencia y la apertura de c√≥digo y datos es parte de una estrategia de soberan√≠a digital.\nIA y Estado: soberan√≠a tecnol√≥gica y cooperaci√≥n regional. La gobernanza de la IA no es solo un problema t√©cnico: es una cuesti√≥n estrat√©gica de Estado. Si no construimos capacidades locales, corremos el riesgo de una nueva dependencia tecnol√≥gica: quedar atrapados entre SIlicon Valley y Shenzehn. Necesitamos soberan√≠a tecnol√≥gica relativa: I+D y talento local, infraestructura digital, datos abiertos bajo normas propias, e innovaci√≥n en nuestro idioma.\nLa regi√≥n debe cooperar: integrar esfuerzos, compartir est√°ndares, negociar mejores condiciones de acceso. Un plan nacional de transformaci√≥n digital con IA deber√≠a incluir inversi√≥n sostenida, apertura de datos p√∫blicos, investigaci√≥n, formaci√≥n de talento, modernizaci√≥n del Estado y articulaci√≥n con actores privados y acad√©micos.\nLa mayor√≠a de los datos valiosos para entrenar y desplegar IA est√°n en manos de plataformas privadas. Esto genera una asimetr√≠a estructural que pone en riesgo la soberan√≠a tecnol√≥gica y la capacidad de innovar localmente. El Estado no necesita centralizar todos los datos, pero s√≠ debe asumir un rol estrat√©gico: garantizar el acceso responsable a datos p√∫blicos de calidad, establecer est√°ndares abiertos de uso y promover una gobernanza √©tica e interoperable. Sin una pol√≠tica de datos, la IA nacional depender√° de insumos ajenos, entrenados con l√≥gicas, sesgos y prioridades que no siempre se corresponden con nuestras necesidades. Una IA al servicio del desarrollo exige que el ecosistema p√∫blico y privado pueda acceder, reutilizar y cuidar los datos como infraestructura com√∫n.\nSin acci√≥n estrat√©gica, seremos meramente consumidores de una tecnolog√≠a definida por otros. Con convicci√≥n y con un rumbo definido, podemos poner la IA al servicio de un desarrollo inclusivo y soberano de nuestro pa√≠s y la regi√≥n."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Opini√≥n",
    "section": "",
    "text": "Federico Sturzenegger tiene raz√≥n: Argentina no necesita una ley de inteligencia artificial\n\n28 de enero, 2026 Daniel Yankelevich\n\n\nFederico Sturzenegger argumenta que Argentina no necesita una ley espec√≠fica de inteligencia artificial, analizando los desaf√≠os regulatorios y proponiendo alternativas‚Ä¶\n\nLeer m√°s ‚Üí\n\n\nUna inteligencia artificial que hable nuestro idioma\n\n10 de septiembre, 2025 Eduardo Levy Yeyati\n\n\n‚ÄúLatamGPT‚Äù, un modelo de inteligencia artificial dise√±ado para Am√©rica Latina. ‚ÄúDime c√≥mo hablas y te dir√© de d√≥nde vienes‚Äù, podr√≠a susurrar un algoritmo‚Ä¶\n\nLeer m√°s ‚Üí\n\n\nNo culpen al algoritmo: ¬øc√≥mo regular la inteligencia artificial en un mundo demasiado humano?\n\n10 de agosto, 2025 Daniel Yankelevich\n\n\nEn 2018, mientras en el Congreso se debat√≠a la despenalizaci√≥n del aborto, el gobierno de la provincia de Salta anunci√≥ un algoritmo que permit√≠a predecir embarazos adolescentes. Esta iniciativa fue recibida con amplias cr√≠ticas y gener√≥ much√≠simo rechazo por su visi√≥n discriminadora‚Ä¶\n\nLeer m√°s ‚Üí\n\n\nInteligencia artificial sin ciencia ficci√≥n: m√°s all√° de los chatbots, hay mucho por hacer\n\n6 de julio, 2025 Macarena Santolaria\n\n\nM√°s que preocuparnos por frenar el ascenso inminente y universal de la IA, en Argentina la principal preocupaci√≥n deber√≠a ser su baja implementaci√≥n en las empresas y en particular en las pymes. La ir‚Ä¶\n\nLeer m√°s ‚Üí\n\n\nDeepfakes, campa√±as sucias y un dec√°logo que parece s√°tira, pero denuncia algo muy real\n\n15 de junio, 2025 Daniel Yankelevich\n\n\nEl a√±o pasado hubo al menos tres casos en que un alumno de secundaria public√≥ videos √≠ntimos de sus compa√±eras. El tema trascendi√≥ porque, en todos los casos, no eran exactamente ellas. Eran videos ed‚Ä¶\n\nLeer m√°s ‚Üí\n\n\nLa paradoja de tercerizar el pensamiento en la IA\n\n15 de enero, 2025 Eduardo Levy Yeyati\n\n\nEl riesgo de tercerizar en la IA las tareas complejas de pensamiento.\n\nLeer m√°s ‚Üí\n\n\nDeepSeek: ¬øatajo a la soberan√≠a tecnol√≥gica o nueva dependencia?\n\n15 de diciembre, 2024 Eduardo Levy Yeyati y Soledad Guilera\n\n\nEduardo Levy Yeyati, director acad√©mico del CEPE, y Soledad Guilera, profesora de la Escuela de Gobierno, escribieron sobre las oportunidades y los desaf√≠os que plantea DeepSeek, la nueva Inteligencia A‚Ä¶\n\nLeer m√°s ‚Üí\n\n\nInteligencia artificial. ¬øEl conocimiento port√°til del futuro?\n\n26 de marzo, 2023 Sebasti√°n Ceria y Daniel Yankelevich\n\n\nEn 1950, Alan Turing cre√≥ el primer m√©todo para comprobar si una computadora pod√≠a responder y reaccionar como lo har√≠a un humano: el test de Turing. En esta prueba, un observador neutral interact√∫a c‚Ä¶\n\nLeer m√°s ‚Üí\n\n\nInteligencia artificial generativa: una cuesti√≥n pol√≠tica\n\n15 de marzo, 2023 Daniel Yankelevich\n\n\nEn las √∫ltimas semanas se habl√≥ sobre el uso de inteligencia artificial generativa. El chatGPT3 para textos o Dall-e y Stability para im√°genes, la IA generativa tiene un gran potencial para transforma‚Ä¶\n\nLeer m√°s ‚Üí\n\n\nDel asombro a la pol√≠tica: la inteligencia artificial sube al estrado\n\n1 de febrero, 2023 Daniel Yankelevich\n\n\nLa inteligencia artificial (IA) nos vuelve a asombrar: el ChatGPT -un modelo que chatea con el usuario y ofrece respuestas extraordinarias, por su precisi√≥n conceptual y por sus habilidades ling√º√≠stic‚Ä¶\n\nLeer m√°s ‚Üí\n\n\n\n\nTodas Pol√≠ticas P√∫blicas Regulaci√≥n Tecnolog√≠a Educaci√≥n Pol√≠tica Deepfakes Democracia Innovaci√≥n Regi√≥n"
  },
  {
    "objectID": "posts/deepseek-atajo-a-la-soberan√≠a-tecnol√≥gica-o-nueva-dependencia.html",
    "href": "posts/deepseek-atajo-a-la-soberan√≠a-tecnol√≥gica-o-nueva-dependencia.html",
    "title": "DeepSeek: ¬øatajo a la soberan√≠a tecnol√≥gica o nueva dependencia?",
    "section": "",
    "text": "Eduardo Levy Yeyati, director acadmico del Cepe, y Soledad Guilera, profesora de la Escuela de Gobierno, escribieron sobre las oportunidades y los desafos que plantea DeepSeek, la nueva Inteligencia Artificial de origen chino. Para la Argentina ‚Äìy para Amrica Latina y el mundo en desarrollo‚Äì, DeepSeek podra ser el inicio de la independencia digital o la puerta de entrada a una nueva dependencia. Atajo a la soberana tecnolgica‚Ä¶? Mientras que OpenAI y Google requieren computadoras de ltima generacin, DeepSeek funciona en hardware ms accesible.Para Amrica Latina, esto significa acceso a IA avanzada sin la necesidad de invertir fortunas en infraestructura. Si gobiernos y empresas juegan bien sus cartas, DeepSeek podra impulsar soluciones locales sin quedar atrapados en la dependencia de Silicon Valley o Pekn. Ms all del acceso, DeepSeek rompe con la idea de que la IA es un juego del tipo ‚Äúganador lleva todo‚Äù. Si cumple lo que promete, podra descentralizar el desarrollo tecnolgico y permitir que los pases en desarrollo definan su propio futuro digital. Lo que podra dar lugar a un ecosistema IA ms dinmico y competitivo, a diferencia de uno en el que la capacidad tecnolgica se concentre en unos pocos monopolios. Pensemos en un agricultor que predice sequas sin depender de Google. Imaginemos un hospital que diagnostica enfermedades sin enviar datos a Silicon Valley. Si la Argentina adopta DeepSeek estratgicamente, podra generar innovaciones propias sin quedar a merced de los gigantes tecnolgicos. La capacidad de DeepSeek para procesar idiomas como espaol y portugus puede fortalecer los ecosistemas de IA en la regin, reduciendo la dependencia de modelos entrenados en ingls. Adems, su eficiencia en hardware de gama media desafa la nocin de que solo pases con energa barata y abundante pueden construir ecosistemas de IA competitivos. En este escenario, Mxico, Colombia o Chile podran posicionarse como centros de innovacin en IA sin depender de clsteres de GPU costosos. Amrica Latina ya cuenta con iniciativas en IA que pueden beneficiarse de este avance. En Brasil, Fiocruz desarrolla soluciones de IA para la agricultura de precisin. En la Argentina, el sistema Prometea agiliza los procesos judiciales. En Chile, la estatal Codelco podra reducir costos operativos y el impacto ambiental en la minera con modelos ms accesibles de IA. En Colombia,startupscomo Quipu estn promoviendo la inclusin financiera a travs de modelos de crdito alternativos. El creciente inters regional en IA se refleja en la reciente iniciativa de Chile: Latam GPT, un modelo de lenguaje abierto que se lanzar este ao. Este movimiento posiciona al pas como un creador de tecnologa y no solo como un consumidor, desafiando el dominio de las grandes potencias de la IA. DeepSeek no es solo un avance tecnolgico; es tambin una herramienta geopoltica. Un gambito deopen sourcepara economas de recursos limitados, un plan de fidelizacin. Respaldado por el Estado chino, DeepSeek es parte de una estrategia para ganar influencia en los pases en desarrollo. No es solo software, es diplomacia digital. Mientras Estados Unidos apuesta por modelos ms potentes, China usa la IA como una va para fortalecer sus lazos estratgicos en mercados estratgicos. Para la Argentina y la regin, esto implica tanto una oportunidad como un riesgo. La dependencia histrica de tecnologas occidentales podra simplemente transformarse en una nueva forma de dependencia tecnolgica si DeepSeek se convierte en la nica alternativa accesible. La leccin es clara: en lugar de quedar atrapados entre Silicon Valley y Pekn, los pases latinoamericanos deben usar esta competencia a su favor, negociando mejores acuerdos de transferencia tecnolgica y diversificando sus asociaciones en IA. La dependencia de un nico proveedor siempre es peligrosa. As como Estados Unidos impuso sanciones en semiconductores para frenar la IA china, la Argentina podra enfrentar restricciones similares si su infraestructura digital queda atrapada en un solo bloque de poder. Para evitar cambiar una dependencia por otra, los gobiernos latinoamericanos deben exigir transparencia en las alianzas de IA, garantizar la capacidad local para entrenar modelos y diversificar sus colaboraciones tecnolgicas. La inversin en IA no es opcional: es una condicin para la competitividad. Sin ella, lasstartupsde la regin tendrn dificultades para escalar, dejando el futuro de la IA en manos de empresas extranjeras.Sin inversin, la regin seguir exportando cerebros e importando innovacin. Amrica Latina cuenta con centros de investigacin en IA de talla mundial, como el CPQD en Brasil, el Cenia de Chile, o nuestro Conicet. Sin embargo, sin inversin sostenida en educacin y en incentivos a la innovacin local, sus mejores talentos seguirn migrando hacia las grandes tecnolgicas extranjeras en lugar de desarrollar soluciones propias. Algunos pases han dado pasos iniciales. En Uruguay, el Plan Ceibal ha promovido la educacin digital, mientras que en Colombia existenbootcampsde IA respaldados por el gobierno.Pero se necesita ms. Nuestros gobiernos deben, entre otras asignaturas pendientes, expandir la formacin en IA desde niveles bsicos hasta avanzados, financiar colaboraciones entre universidades ystartups, fomentar el emprendimiento en IA para evitar la fuga de talentos e impulsar regulaciones que equilibren la innovacin con la soberana digital. Alianzas regionales como Mercosur, Celac y la Alianza del Pacfico pueden jugar un rol clave en la negociacin de acceso equitativo a la IA y en la creacin de regulaciones de soberana de datos. Una estrategia fragmentada solo hara a la regin ms vulnerable a las condiciones impuestas por las superpotencias tecnolgicas. La Argentina tiene la oportunidad de definir su futuro digital, pero solo si acta con determinacin. Sin un plan claro y una accin decidida, el pas corre el riesgo de seguir siendo solo un consumidor de IA en un juego donde otros tienen el control. La inversin en educacin, investigacin e innovacin, o las alianzas regionales para armonizar regulaciones y agregar recursos escasos, no son una opcin; son una necesidad cada vez ms urgente.De lo contrario, la tecnologa no har ms que ampliar la brecha de desarrollo. La pregunta no es si la IA transformar a la Argentina, sino quin definir su futuro cuando lo haga.\nCapacitacin sobre adopcin de inteligencia artificial en empresas Despus de la COP30: las promesas se traducen en acciones? Charla sobre los resultados de la Conferencia de las Partes de Cambio Climtico\nDebate sobre el impacto de la IA en la democracia Est disponible la nueva publicacin trimestral\nInnovacin vs Regulacin: el dilema de la Inteligencia Artificial ltimo encuentro del ciclo de charlas de Inteligencia Artificial y Polticas Pblicas Transformacin digital e inclusin financiera juvenil: hallazgos clave del estudio de CEPE Di Tella Presentacin de los resultados de la investigacin Una dcada de economa del comportamiento en Latinoamrica Est disponible la nueva publicacin del ndice de Conflictividad Laboral\nInteligencia artificial y escolarizacin: ruptura o continuidad?\nEst disponible la publicacin de junio del ndice de Conflictividad Laboral Presentacin de Juan Cruz Loureiro en Tech4Impact 2024 Qu es la inteligencia artificial? Avances de un fenmeno que lleg para quedarse\nLa atencin de Gobierno en la era digital: El caso Boti en la Ciudad de Buenos Aires Sali la publicacin de marzo del ndice de Conflictividad Laboral Nueva Publicacin: Complejidad y polticas pblicas: una agenda de presente y futuro Este documento recopila los temas tratados durante la 6.a Sali la publicacin de diciembre del ndice de Conflictividad Laboral\nPresentacin del informe coescrito con la RREI Presentacin del informe ‚ÄúDesigualdades heredadas‚Äù Discusin sobre el reporte publicado por RED CAF 2022\nEl 24 de agosto se realiz la 6. Se present el Documento de Polticas Pblicas de Beatriz Toribio junto a un panel de expertos. Presentacin del libro ‚ÄúLa transicin energtica en la visin de sus protagonistas‚Äù Conversacin sobre el libro publicado por el Instituto Torcuato Di Tella Sali la publicacin de abril del ndice de Conflictividad Laboral\nNueva publicacin: Energa, cambio climtico y crecimiento Este documento recopila los temas tratados durante la 5.a Presentacin de investigacin: Los adolescentes y las finanzas Investigacin sobre conocimientos y hbitos en Argentina\nSe presentaron los resultados obtenidos en la Ciudad de Buenos Aires y en Mendoza, propiciando un espacio para la reflexin acerca del sostenimiento y escalabilidad de esta iniciativa Presentacin de Actualizacin de Indicadores de Emisiones Energticas en Argentina Se presentaron los resultados actualizados a junio de 2022 del proyecto desarrollado en conjunto con la Fundacin Torcuato Di Tella.\nGastn Gertner, director ejecutivo del CEPE, habl en el evento organizado en el Congreso\nEl 25 de agosto se realiz la 5. Conversamos con Gastn, quien a comienzos de noviembre asumi como Director Ejecutivo del CEPE. A pocos das de terminar el ao, nos gustara compartir con ustedes algunos de los hechos ms destacados.\nQu aprendimos del proceso de participacin de la sociedad civil en educacin\nQu aprendieron sobre educacin las empresas tecnolgicas?\nMs de 25 oradores debatieron sobre educacin en la IV\nQu hacer con los estudiantes excluidos en la pandemia? Expusieron funcionarios de la regin\nEl director acadmico del CEPE cre una encuesta para estudiar las dimensiones socioeconmicas detrs del debate sobre la presencialidad escolar en pandemia.\nFue reconocido por el Global Go To Think Tank Index Report del 2020. Una seleccin de los contenidos que lograron mayor repercusin durante el ao pasado.\nA pocos das de terminar el 2020, nuestro balance de fin de ao.\nSe inaugur el 2 ciclo de charlas Pensando la pospandemia\n[ / Av. Figueroa Alcorta 7350 (C1428BCW) Senz Valiente 1010 (C1428BIJ) Ciudad de Buenos Aires, Argentina Cmo llegar? / Polticas de privacidad Adems, en alianza con la Formacin Ejecutiva en Polticas Pblicas de la Escuela de Gobierno ofrecemos los siguientes cursos:\n**\n\nPublicado originalmente en La Naci√≥n\n\n\n\n\nTodas Pol√≠ticas P√∫blicas Regulaci√≥n Tecnolog√≠a Educaci√≥n Pol√≠tica Deepfakes Democracia Innovaci√≥n Regi√≥n"
  },
  {
    "objectID": "posts/del-asombro-a-la-politica.html",
    "href": "posts/del-asombro-a-la-politica.html",
    "title": "Del asombro a la pol√≠tica: la inteligencia artificial sube al estrado",
    "section": "",
    "text": "La inteligencia artificial (IA) nos vuelve a asombrar: el ChatGPT -un modelo que chatea con el usuario y ofrece respuestas extraordinarias, por su precisi√≥n conceptual y por sus habilidades ling√º√≠sticas- est√° en el foco de atenci√≥n. Pero la IA no es solo una cuesti√≥n tecnol√≥gica: la pregunta sobre c√≥mo este y otros desarrollos pueden mejorar la vida de las personas es una pregunta pol√≠tica. Y es una pregunta que las y los actores de la vida pol√≠tica argentina tienen que empezar a formularse cuanto antes.\nTomemos un ejemplo muy cotidiano, las multas de tr√°nsito. ¬øQui√©n no sufri√≥ una multa de tr√°nsito injusta y se ha resignado a pagarla para evitar el laberinto kafkiano que implica ir detr√°s de la ra√≠z de esa injusticia? La empresa DoNotPay.com es una startup que usa IA para discutir multas. Es semejante a contratar un abogado robot: uno le indica la multa, la jurisdicci√≥n y la empresa se ocupa. Joshua Browder, su CEO y fundador, no se cansa de repetir que cre√≥ la empresa -que presta servicios en los EE.UU.- para representar a la gente en casos que ning√∫n abogado tomar√≠a: multas de tr√°nsito, pero tambi√©n reclamos de consumidores en general.\nRecientemente, DoNotPay se hizo m√°s conocida por ser parte del primer juicio con un abogado robot. Incluso, en uno de los casos, que debe resolverse personalmente en un tribunal frente a frente a un juez o una jueza, la persona va a concurrir con anteojos conectados a internet y va a recibir la informaci√≥n y las respuestas que debe dar mediante auriculares. Es decir que la inteligencia artificial va a susurrar las respuestas al o√≠do del abogado. Adem√°s, la empresa fue todav√≠a m√°s lejos: ofrece un mill√≥n de d√≥lares para el abogado que se anime a llevar a su robot-abogado a defender un caso frente a la Corte Suprema de los Estados Unidos. En suma, los usos que la empresa hace de la IA son una muestra de c√≥mo esta tecnolog√≠a puede servir para mejorar el funcionamiento de una esfera tan sensible como la Justicia.\nLos nuevos desarrollos en Inteligencia Artificial -como el ChatGPT y otros- permitir√°n a DoNotPay ser mucho m√°s efectiva a la hora de presentar reclamos de consumidores y consumidoras por canales digitales, e incluso chatear y discutir con representantes de Atenci√≥n al Cliente. Reclamos por problemas menores en productos -que hasta ahora estaban reservados a gente con mucho tiempo libre- podr√°n ser ‚Äúdelegados‚Äù en estos sistemas: es cuesti√≥n de entrenar el modelo con suficiente informaci√≥n de sentencias y otras fuentes legales. Esto puede ser de gran ayuda para casos que nunca llegan a juicio o para realizar un reclamo formal: las corporaciones conf√≠an en que muy poca gente tiene el tiempo o la energ√≠a para seguir el reclamo. Las IA podr√≠an funcionar, bien miradas, como ‚ÄúRobin Hoods‚Äù algor√≠tmicos.\nPorque no se cansan y persiguen su objetivo hasta el final: pueden equivocarse, pero no rendirse. En un futuro -no sencillo de realizar, pero posible- ayudar√≠a a mejorar el acceso a la justicia de los grupos m√°s vulnerables.\nAhora, pensemos un momento la posibilidad de aplicar esta tecnolog√≠a en un sistema como la justicia argentina. La realidad es que no estamos listos: tenemos una justicia que usa procedimientos arcaicos y que no tiene las capacidades como para gestionar este tipo de innovaciones. En muchos casos, ni siquiera tiene las herramientas para entender lo que est√° sucediendo y los potenciales riesgos que vienen asociados al uso de inteligencia artificial. Imaginemos, por ejemplo, un estudio de abogados que utiliza un programa de inteligencia artificial an√°logo al que describimos. Un programa capaz de ingresar 50.000 demandas -coherentes, bien escritas, que cumplen todos los requisitos ‚Äì por d√≠a durante un mes: esto har√≠a colapsar cualquier sistema, en Argentina y en el mundo. Y a eso sumemos los problemas ‚Äúcl√°sicos‚Äù cuando queremos aplicar IA a la gesti√≥n de pol√≠ticas p√∫blicas: problemas de sesgo, explicabilidad, responsabilidad, entre otros, que no se resuelven comprando una tecnolog√≠a.\nHay mucho que hacer si queremos que la IA sea un instrumento de cambio positivo en una esfera como la Justicia (y en muchas otras). Ayudar a respuestas m√°s r√°pidas, actuar como primeros filtros en casos m√°s simples y asistir a los funcionarios y funcionarias, facilitando y ordenando el trabajo. A una demanda de Chat GPT, responder con un Chat GPT judicial. Para que esto ocurra, no se trata solo de incorporar una tecnolog√≠a: se trata de modificar procedimientos y formas de trabajo, se trata de capacitaci√≥n y de cambios en pol√≠ticas p√∫blicas.\nHay much√≠simo para hacer si queremos ir del asombro a la pol√≠tica. Un primer paso es dejar de hablar de la innovaci√≥n tecnol√≥gica como un acontecimiento extranjero. Decir que la IA es una cuesti√≥n pol√≠tica es decir que debe ser pensada, discutida y decidida por las fuerzas de la vida pol√≠tica argentina: sus dirigentes, sus cuadros, sus t√©cnicos. Para ello, es necesario estar a la altura de tales discusiones. No basta con tocar de o√≠do. Y 2023 es un a√±o electoral: en las elecciones se discuten -o se deber√≠an discutir- programas y temas sensibles a la ciudadan√≠a y a la mejora de las condiciones de vida. ¬øNo ser√≠a revolucionario que un tema como la IA est√© presente en alguna de esas conversaciones?** ¬øNo hablar√≠a de l√≠deres y lideresas pol√≠ticas en sinton√≠a no solo con los problemas muy serios del presente, sino con las posibles soluciones que nos ofrece el futuro?**\n\nPublicado originalmente en el diario La Naci√≥n\n\n\n\n\nTodas Pol√≠ticas P√∫blicas Regulaci√≥n Tecnolog√≠a Educaci√≥n Pol√≠tica Deepfakes Democracia Innovaci√≥n"
  },
  {
    "objectID": "posts/la-paradoja-de-tercerizar-el-pensamiento-en-la-ia.html",
    "href": "posts/la-paradoja-de-tercerizar-el-pensamiento-en-la-ia.html",
    "title": "La paradoja de tercerizar el pensamiento en la IA",
    "section": "",
    "text": "El director acad√©mico del CEPE escribi√≥ sobre el riesgo de tercerizar en la IA las tareas complejas de pensamiento. Como ya dijimos aqu√≠, la IA domina el conocimiento expl√≠cito ‚Äìel que puede documentarse y transmitirse: ‚Äútokenizarse‚Äù‚Äì, a diferencia del t√°cito: saber pr√°ctico formado en la experiencia humana. Esto, que abre la puerta a una complementaci√≥n natural entre el humano y el algoritmo, tambi√©n genera una paradoja: el uso intensivo de IA en tareas complejas socava las condiciones que permiten formar ese conocimiento t√°cito que ‚Äìal menos por ahora‚Äì dibuja uno de los l√≠mites de la sustituci√≥n tecnol√≥gica. Una investigaci√≥n reciente de Anthropic, basada en el an√°lisis de conversaciones estudiantiles con chatbot Claude, encontr√≥ que casi la mitad (47%) de las interacciones con IA son ‚Äúconversaciones directas‚Äù, con m√≠nima participaci√≥n, orientadas a resolver consultas r√°pidamente en lugar de fomentar el di√°logo o el intercambio. M√°s revelador a√∫n: cuando se analizaron las tareas cognitivas que los estudiantes delegan a la IA usando la Taxonom√≠a de Bloom, se descubri√≥ que principalmente tercerizan funciones de orden superior como crear (39.8%) y analizar (30.2%), mientras que recordar representa apenas el 1.8%. Ciencias de la Computaci√≥n lidera la adopci√≥n (38.6% de conversaciones con solo 5.4% de graduados), seguidas por Ciencias Naturales y Matem√°ticas. Humanidades y Salud tienen menor uso relativo. Esto que parece un problema acad√©mico es, en realidad, un s√≠ntoma de una transformaci√≥n cognitiva m√°s profunda.\nEl conocimiento t√°cito se cultiva en la experiencia: es la intuici√≥n que alerta a un m√©dico pese a estudios normales; el juicio de un maestro para decidir cu√°ndo presionar o dar espacio; la pericia de un ingeniero para detectar fallas que las simulaciones no captan. Este conocimiento t√°cito est√° ‚Äúescrito en el cuerpo‚Äù: en las v√≠as neuronales formadas por la pr√°ctica, en la memoria muscular de la repetici√≥n, en el reconocimiento que surge del contacto con la complejidad del mundo real. Aqu√≠ es donde la paradoja se vuelve m√°s clara: la IA es tan buena manejando conocimiento expl√≠cito que cada vez m√°s nos sentimos tentados a tercerizar nuestro pensamiento. Pero al hacerlo, corremos el riesgo de atrofiar la formaci√≥n del conocimiento t√°cito que la IA no puede replicar. Consideremos lo que sucede cuando los estudiantes buscan consistentemente respuestas directas de la IA en lugar de luchar con los problemas por s√≠ mismos. Pueden completar tareas eficientemente, pero se pierden la lucha cognitiva que construye resistencia intelectual y desarrolla comprensi√≥n intuitiva. Obtienen el conocimiento expl√≠cito ‚Äìlos hechos, las respuestas correctas‚Äì pero no desarrollan el conocimiento t√°cito que proviene de enfrentarse con la incertidumbre, cometer errores y aprender a confiar en su propio juicio. El estudio de Anthropic tambi√©n identific√≥ patrones preocupantes en el uso ‚Äúdirecto‚Äù de IA: respuestas a preguntas de opci√≥n m√∫ltiple en machine learning, respuestas directas a ex√°menes de idiomas, y reescritura de textos de marketing para evitar detectores de plagio. Como el reporte advierte: ‚ÄúExisten preocupaciones leg√≠timas de que los sistemas de IA puedan proporcionar una muleta para los estudiantes, limitando el desarrollo de habilidades fundamentales necesarias para apoyar el pensamiento de orden superior‚Äù. El problema se extiende m√°s all√° de las aulas. La trampa de Turing‚Äìel escenario donde delegamos tanto pensamiento a la IA que perdemos las experiencias que generan expertise humana‚Äì ya tiene precedentes. Pensemos c√≥mo el GPS ha reducido nuestras habilidades espaciales, o c√≥mo las calculadoras alteraron el c√°lculo mental. Ahora imaginemos esta din√°mica desarroll√°ndose en cada dominio del trabajo intelectual. Creamos un c√≠rculo vicioso donde:\n\nLa IA maneja tareas de conocimiento expl√≠cito m√°s eficientemente que los humanos\nLos humanos dependen cada vez m√°s de la IA para estas tareas\nLos humanos pierden oportunidades para desarrollar conocimiento t√°cito a trav√©s de la pr√°ctica\n\nEs la distop√≠a silenciosa de la pel√≠cula Wall-E, donde, tras delegar toda la actividad a sistemas automatizados, los humanos terminan con sus cuerpos y mentes atrofiados. ¬øCorremos el riesgo de algo similar con nuestra experiencia intelectual? Cuando dejamos que los modelos de lenguaje nos ‚Äúatiendan‚Äù el conocimiento, nos volvemos consumidores pasivos de respuestas perfectamente formuladas, pero dejamos de ejercitar el juicio que da forma a nuestra inteligencia. El m√∫sculo cognitivo tambi√©n se atrofia cuando no se entrena. La iron√≠a es que el conocimiento t√°cito se vuelve m√°s valioso, no menos, en un mundo dominado por IA. Cuando el conocimiento expl√≠cito se convierte en commodity, el juicio humano es el recurso escaso. La capacidad de saber cu√°ndo confiar en los resultados de la IA, c√≥mo formular las preguntas correctas y cu√°ndo anular las recomendaciones algor√≠tmicas se vuelve crucial. Como reconoce la propia IA sobre sus limitaciones: los modelos de lenguaje aprenden ‚Äúanalizando patrones y estructuras en grandes cantidades de datos textuales‚Äù pero carecen de ‚Äúla capacidad de adquirir o aplicar [conocimiento t√°cito] de la misma manera que una persona lo har√≠a a trav√©s de la pr√°ctica y experiencia directa‚Äù. En lugar de usar la IA para evitar pensar, necesitamos enfoques donde potencie ‚Äìy no reemplace‚Äì el desarrollo cognitivo.\nEl objetivo no es competir con la IA en conocimiento expl√≠cito, sino cultivar las capacidades √∫nicamente humanas que emergen de la experiencia, la pr√°ctica y el aprendizaje encarnado ‚Äìvivido, irrepetible‚Äì, an√°logo en el conocimiento a lo que el ‚Äúaura‚Äù es en la creatividad. En lugar de enfocarnos principalmente en transferencia de informaci√≥n, necesitamos enfatizar el desarrollo de juicio, intuici√≥n y el tipo de sabidur√≠a pr√°ctica que solo puede provenir de enfrentarse directamente con situaciones complejas y ambiguas. Esto requiere dise√±ar interacciones que preserven el desarrollo cognitivo: en educaci√≥n, pidiendo que los estudiantes compartan sus prompts junto con las tareas, creando evaluaciones que prioricen el juicio y enfatizando el aprendizaje experiencial; en el trabajo, usando IA para recopilar sin reemplazar la decisi√≥n humana y garantizando experiencia pr√°ctica. La evidencia emp√≠rica respalda estas preocupaciones: estudios recientes documentan reducciones en el esfuerzo cognitivo y el pensamiento cr√≠tico asociadas al uso intensivo de IA. Sin embargo, la paradoja de la tercerizaci√≥n apunta a algo m√°s fundamental: las mismas capacidades de IA que hacen el conocimiento expl√≠cito universalmente accesible podr√≠an socavar el desarrollo del conocimiento t√°cito que nos mantiene relevantes. Esta paradoja tambi√©n se√±ala una soluci√≥n. Al entender qu√© hace √∫nico e irreemplazable al conocimiento humano, podemos dise√±ar interacciones con IA que fortalezcan nuestra agencia intelectual. El futuro no ser√° de quienes compitan con la IA, sino de quienes sepan pensar con ella, preservando el aprendizaje experiencial que produce el irreemplazable discernimiento humano. El desaf√≠o no es solo tecnol√≥gico: es qu√© tipo de aprendices y pensadores elegimos ser en la era de la IA. Como dec√≠a Arist√≥teles, hay saberes que solo emergen del encuentro directo con el mundo. La paradoja de la tercerizaci√≥n cognitiva no es tecnol√≥gica, sino pedag√≥gica: no es solo lo que la IA no hace, sino lo que dejamos de hacer al usarla como atajo. Lo que perdemos no es una habilidad puntual, sino la experiencia que la forma.\n\nPublicado originalmente en La Naci√≥n\n\n\n\n\nTodas Pol√≠ticas P√∫blicas Regulaci√≥n Tecnolog√≠a Educaci√≥n Pol√≠tica Deepfakes Democracia Innovaci√≥n Regi√≥n"
  },
  {
    "objectID": "posts/ia-generativa-cuestion-politica.html",
    "href": "posts/ia-generativa-cuestion-politica.html",
    "title": "Inteligencia artificial generativa: una cuesti√≥n pol√≠tica",
    "section": "",
    "text": "En las √∫ltimas semanas se habl√≥ sobre el uso de inteligencia artificial generativa. El chatGPT3 para textos o Dall-e y Stability para im√°genes, la IA generativa tiene un gran potencial para transformar la manera en que se produce y consume contenido. Ahora bien, esta tecnolog√≠a trae consigo amenazas y desaf√≠os, sobre todo si pensamos en el posible impacto en los sistemas democr√°ticos. Fake news, desinformaci√≥n, trolls colapsando sistemas de comunicaci√≥n oficiales.¬†\nQu√© es cada cosa, qu√© est√°n haciendo los Estados en el mundo y propuestas para trabajar el tema en¬† Argentina.\n\nPublicado originalmente en Fundar\n\n\n\n\nTodas Pol√≠ticas P√∫blicas Regulaci√≥n Tecnolog√≠a Educaci√≥n Pol√≠tica Deepfakes Democracia Innovaci√≥n"
  },
  {
    "objectID": "posts/conocimiento-portatil-futuro.html",
    "href": "posts/conocimiento-portatil-futuro.html",
    "title": "Inteligencia artificial. ¬øEl conocimiento port√°til del futuro?",
    "section": "",
    "text": "En 1950, Alan Turing cre√≥ el primer m√©todo para comprobar si una computadora pod√≠a responder y reaccionar como lo har√≠a un humano: el test de Turing. En esta prueba, un observador neutral interact√∫a con dos interlocutores: uno de ellos es una computadora y el otro es un humano, pero el observador no sabe cu√°l es cu√°l. Si este √∫ltimo no logra descubrir a la computadora mediante una serie de preguntas, decimos que ha superado el test de Turing, ya que contesta ‚Äúigual que un humano‚Äù. Cuando el c√©lebre matem√°tico desarroll√≥ su test, la perspectiva de dise√±ar una computadora que pudiera superarlo era lejana. Hoy, en cambio, la sorpresa es que la computadora no supere el test.\nM√°s a√∫n, con el reciente lanzamiento de la nueva versi√≥n del ChatGPT, un desarrollo de OpenAI, las respuestas parecen no solo indistinguibles, sino muchas veces mejores -en cuanto a su claridad conceptual y ling√º√≠stica- a las que puede ofrecer un humano. De hecho, en algunos campos del trabajo intelectual, las computadoras ya vienen superando el test de Turing cotidianamente con actividades que suplen al trabajo humano. Por ejemplo, hace muy poco tiempo exist√≠a (existe todav√≠a) una labor -la taquigraf√≠a en sus versiones m√°s o menos profesionales- que consist√≠a en ‚Äúdesgrabar‚Äù una clase o una reuni√≥n a partir de una cinta. Hoy, eso mismo se puede hacer desde un audio o un video en forma completamente automatizable usando IA. El ejemplo es b√°sico, pero, ¬øhasta d√≥nde puede extrapolarse? ¬øQu√© capacidades pueden aprenderse o facilitarse usando IA?\nImaginemos ahora un test alternativo al de Turing, con un escenario y componentes similares, pero otro objetivo: averiguar si la tecnolog√≠a IA puede proporcionar saberes de forma extraordinaria y ‚Äúproducir‚Äù un experto en tiempo r√©cord. En una habitaci√≥n tenemos un experto en cierta tem√°tica; en otra, una persona sin conocimientos espec√≠ficos, pero asistido por una ‚Äúmochila de IA‚Äù que est√° capacitado para usar y le sirve para obtener respuestas sobre esa tem√°tica; un tercer participante, neutral, tiene que interactuar con ambos. Si este √∫ltimo no puede distinguir a la persona experta de la inexperta, el test est√° aprobado. Nuestra prueba es una especulaci√≥n, pero una especulaci√≥n necesaria, porque nos permite formularnos las preguntas correctas de cara al futuro: ¬øes posible que una persona, con la asistencia tecnol√≥gica adecuada, pueda dominar una capacidad o saber a una velocidad in√©dita? ¬øPueden estos dispositivos de IA ser instrumentos para reducir la diferencia entre expertos y no expertos? Para ser m√°s claros, ¬øpuede la IA ser un instrumento para acortar la brecha de capacidades y de saberes? Existen elementos para dar una respuesta afirmativa.\nEn primer lugar, la disrupci√≥n creada por la IA es un hecho indisputable: la IA est√° produciendo cambios en la manera que recibimos y construimos conocimientos. Pensemos en los videos de YouTube que ense√±an soluciones a una vasta y variada gama de problemas a trav√©s de tutoriales: ¬øno es una muestra clara de c√≥mo la tecnolog√≠a ya est√° ayudando a achicar la brecha de conocimientos, a aumentar y potenciar las capacidades de los no expertos? En segundo lugar, estamos seguros de que la formaci√≥n que se requiere para interactuar con IA es m√°s f√°cil de adquirir que una educaci√≥n formal de varios a√±os. Pensemos en poblaciones que tuvieron una educaci√≥n b√°sica deficitaria: la disrupci√≥n producida por la IA puede ser un instrumento para ‚Äúsaltar‚Äù la brecha de formaci√≥n. Insistamos con el potencial: puede serlo, si esa ‚Äúmochila‚Äù se piensa y planifica en una estrategia integral de desarrollo inclusivo y sustentable.\nDemos un ejemplo de la IA como salto en el dominio de una determinada disciplina: la programaci√≥n. Las diferencias de productividad entre los programadores expertos y los programadores amateur es muy grande. En varios an√°lisis que la ACM (Asociaci√≥n Profesional Internacional de Computaci√≥n) realiz√≥ a lo largo de los a√±os, report√≥ diferencias de 700% en rendimiento entre ambos perfiles. Por otro lado, la IA por s√≠ sola no est√° capacitada para programar sin supervisi√≥n directa: seguramente sus resultados son peores que los de un programador amateur. Pero un programador amateur con determinado entrenamiento espec√≠fico y acceso a asistentes como los que ya existen (Copilot, por ejemplo) puede mejorar mucho y reducir la brecha con un programador excelente, aunque este tenga acceso a la misma herramienta. Es decir que la IA, en este campo, ayuda a reducir la brecha de capacidades, porque tiene un mayor efecto positivo en el no experto que en el experto. No es obvio que la vaya a tener en otros campos, pero s√≠ que la posibilidad existe.\nHay algo que s√≠ es obvio o evidente: esas ‚Äúmochilas IA‚Äù no van a ser un bien com√∫n en el futuro y no van a ser accesibles para todos por el solo hecho de que vayan a existir. Incluso, si fu√©ramos a usarlas para saltar brechas, ¬øqui√©n tendr√° esas ‚Äúmochilas‚Äù? ¬øqu√© formaci√≥n debe tener alguien para poder aprovechar todo su potencial? ¬øse podr√°n fabricar como se fabrica un martillo? ¬øqui√©n puede o debe fabricarlas? ¬øqui√©n financiarlas?\nEntonces, ¬øpuede la IA ayudar a reducir la brecha de capacidades y de saberes? La respuesta est√° en nuestras manos, como sociedad. Se trata de definir una estrategia para usarla en esa direcci√≥n. Lo que ocurra puede tener consecuencias opuestas: ampliar o reducir las diferencias existentes.\nEs muy dif√≠cil que estos dispositivos vayan a ser instrumentos de igualaci√≥n si solo vemos pasar el tren del futuro desde el terrapl√©n del statu quo. La estrategia del laissez faire agranda la brecha entre sociedades que invierten billones de d√≥lares en desarrollar estas capacidades y sociedades que no. Por eso, es imprescindible tener pol√≠ticas p√∫blicas que empujen la posibilidad de que la IA forme parte de una din√°mica virtuosa que ayude a nivelar para arriba.\nEntonces, ¬øpuede la IA ayudar a reducir la brecha de capacidades y de saberes? La respuesta est√° en nuestras manos, como sociedad. Se trata de definir una estrategia para usarla en esa direcci√≥n. Lo que ocurra puede tener consecuencias opuestas: ampliar o reducir las diferencias existentes. El resultado no es inevitable ni est√° dado: se trata de c√≥mo decidimos actuar de cara a esta y a otras innovaciones tecnol√≥gicas. Debemos investigar, dise√±ar e implementar pol√≠ticas p√∫blicas que incentiven el desarrollo de una IA inclusiva, capaz de revolucionar la educaci√≥n, el mercado de trabajo y el potencial econ√≥mico de nuestro pa√≠s: ese es un camino posible para conseguir una sociedad m√°s igualitaria. Quiz√°s estemos ante una de las mayores oportunidades con potencial igualador de los √∫ltimos tiempos, pero debemos asegurarnos que la tecnolog√≠a sea utilizada para reducir la brecha de conocimientos y no para generar el efecto contrario.\n\nPublicado originalmente en el diario La Naci√≥n\n\n\n\n\nTodas Pol√≠ticas P√∫blicas Regulaci√≥n Tecnolog√≠a Educaci√≥n Pol√≠tica Deepfakes Democracia Innovaci√≥n"
  },
  {
    "objectID": "investigacion/encuesta-pymes.html",
    "href": "investigacion/encuesta-pymes.html",
    "title": "Encuesta Nacional sobre Adopci√≥n de IA - PyMES",
    "section": "",
    "text": "Sobre esta investigaci√≥n\nLas peque√±as y medianas empresas (PyMES) representan un componente fundamental de la econom√≠a argentina, generando empleo y contribuyendo significativamente al PIB. Sin embargo, su capacidad para adoptar tecnolog√≠as emergentes como la inteligencia artificial presenta desaf√≠os √∫nicos que requieren atenci√≥n espec√≠fica.\nEsta encuesta busca comprender el estado actual de la adopci√≥n de IA en las PyMES argentinas, identificando las barreras que enfrentan, las oportunidades que perciben y las estrategias que est√°n implementando para integrar estas tecnolog√≠as en sus procesos productivos y de gesti√≥n.\n\n\nObjetivos de la investigaci√≥n\n\nMapear el nivel de adopci√≥n de IA en diferentes sectores de PyMES\nIdentificar las principales barreras t√©cnicas, econ√≥micas y de conocimiento\nAnalizar el impacto de la IA en la productividad y competitividad\nEvaluar las necesidades de capacitaci√≥n y apoyo institucional\nProponer pol√≠ticas p√∫blicas espec√≠ficas para PyMES\n\n\n\nMetodolog√≠a\nLa encuesta se realizar√° mediante un panel representativo de PyMES argentinas, estratificadas por sector econ√≥mico, tama√±o y regi√≥n geogr√°fica. Se espera recopilar datos durante el segundo semestre de 2025.\n\n\nResultados esperados\nLos resultados de esta investigaci√≥n permitir√°n:\n\nDise√±ar pol√≠ticas p√∫blicas espec√≠ficas para la adopci√≥n de IA en PyMES\nIdentificar sectores prioritarios para intervenciones\nDesarrollar programas de capacitaci√≥n y apoyo t√©cnico\nGenerar evidencia para la toma de decisiones empresariales"
  },
  {
    "objectID": "nosotros.html",
    "href": "nosotros.html",
    "title": "Nodo Argentino de Inteligencia Artificial",
    "section": "",
    "text": "¬øQu√© queremos lograr?\nLa IA puede aumentar la productividad econ√≥mica si existe un ecosistema y acciones coordinadas y eso va a depender de las decisiones que tomemos hoy y de las pol√≠ticas que implementemos Para eso, nos proponemos traducir datos en acci√≥n y generar impactos concretos en distintos niveles:\n\nEmpresas: generar inteligencia estrat√©gica que permita acelerar la adopci√≥n de IA, mejorar productividad y competir regional e internacionalmente.\nGobiernos: proveer evidencia y propuestas para anticipar pol√≠ticas p√∫blicas que sean √©ticas, competitivas y adaptadas a la realidad regional.\nSociedad: impulsar innovaci√≥n en educaci√≥n y capacitaci√≥n laboral que reduzca desigualdades y prepare a las personas para empleos de calidad en la era de la IA.\nRegi√≥n: liderar una red de colaboraci√≥n que conecte a Argentina con Am√©rica Latina y posicione a la regi√≥n en la discusi√≥n global sobre IA.\n\n\nNosotros\nnadIA es el primer espacio en Argentina dedicado a producir datos, investigaci√≥n y proyectos innovadores sobre inteligencia artificial, con foco en pol√≠ticas p√∫blicas y desarrollo econ√≥mico. Queremos que la IA sea un vector para impulsar un desarrollo inclusivo, competitivo y sostenible para Argentina y la regi√≥n.\n\nCEPE es el centro de pol√≠ticas p√∫blicas basadas en evidencia de la Escuela de Gobierno de la Universidad Torcuato Di Tella.\n\n\nFundar es un centro de innovaci√≥n en pol√≠ticas de desarrollo que busca impulsar transformaciones estructurales a partir de soluciones concretas que puedan ser aplicadas y testeadas.\n\n\n\n\nCEPE\nFundar\n\n\n\n\nEduardo Levy Yeyati\nDaniel Yankelevich\n\n\nMariana Barrera\nJuan Pablo Ruiz Nicolini\n\n\nDar√≠o Judzik\nAgustina Bendersky\n\n\nGuadalupe Dorna\nJuan O‚ÄôFarrell\n\n\nSoledad Guilera\nJohanna Cristallo\n\n\n\nMariana Kunst\n\n\n\nAlejandro Avenburg\n\n\n\nMacarena Santolaria"
  }
]